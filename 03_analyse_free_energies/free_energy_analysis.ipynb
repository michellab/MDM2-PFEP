{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8dffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from cinnabar import stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c47f2a",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae635a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rmse(predictions, targets):\n",
    "    \"\"\"Calculates RMSE using sqrt(mean((predicted_vals - target_vals)^2))\"\"\"\n",
    "    return np.sqrt(sklearn.metrics.mean_squared_error(targets, predictions))\n",
    "\n",
    "def calculate_mae(predictions, targets):\n",
    "    \"\"\"Calculates MAE using mean(abs(predicted_vals - target_vals))\"\"\"\n",
    "    # mae = np.mean(np.absolute(predictions - targets))\n",
    "    # return mae\n",
    "    return sklearn.metrics.mean_absolute_error(targets, predictions)\n",
    "\n",
    "def specific_pattern_match(cell, pattern):\n",
    "    if pd.isna(cell):\n",
    "        return False\n",
    "    return bool(re.search(pattern, str(cell)))\n",
    "\n",
    "def arr_to_kJ2kcal(arr):\n",
    "    from scipy.constants import calorie\n",
    "    kJ2kcal = 1 / calorie\n",
    "    return arr * kJ2kcal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde1a7ec",
   "metadata": {},
   "source": [
    "# Experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb46ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXPERIMENTAL ITC RESULTS\n",
    "am_exp_ddg_kcal = {\"v14g\": 1.13, \"t16g\": 3.09, \"q18g\": 0.89, \"i19g\": 4.09, \"t16g_i19g\": 3.92}\n",
    "nutlin_exp_ddg_kcal = {\"v14g\": 0.11, \"t16g\": 0.20, \"q18g\": 0.20, \"i19g\": 0.35, \"t16g_i19g\": 0.20}\n",
    "\n",
    "am_exp_ddg_kcal_df = pd.DataFrame.from_dict(am_exp_ddg_kcal, orient=\"index\", columns=[\"ddG (kcal/mol)\"])\n",
    "nutlin_exp_ddg_kcal_df = pd.DataFrame.from_dict(nutlin_exp_ddg_kcal, orient=\"index\", columns=[\"ddG (kcal/mol)\"])\n",
    "\n",
    "am_exp_ddg_kcal_df, nutlin_exp_ddg_kcal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b262ffb",
   "metadata": {},
   "source": [
    "## EQ 0 to 100 % (Forward Convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba45a4",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25e603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_df_full = pd.read_csv('eq_fep_analysed_results_0_to_100/am_df_full.csv')\n",
    "apo_df_full = pd.read_csv('eq_fep_analysed_results_0_to_100/apo_df_full.csv')\n",
    "nutlin_df_full = pd.read_csv('eq_fep_analysed_results_0_to_100/nutlin_df_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5985ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_df_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80364f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_rmse = {}\n",
    "temporal_rmse_lower = {}\n",
    "temporal_rmse_upper = {}\n",
    "temporal_mae = {}\n",
    "temporal_std = {}\n",
    "temporal_am_pred_ddg_std = []\n",
    "temporal_nutlin_pred_ddg_std = []\n",
    "\n",
    "time_start_ns = 0 # ns\n",
    "\n",
    "for time_end_ns in range(10, 110, 10):\n",
    "    time_end = time_end_ns * 1000 # ns to ps\n",
    "\n",
    "\n",
    "    # need to use the pandas query method to filter the dataframes because saving to csv did not save the multiindex\n",
    "    am_open_slice_results_df = am_df_full[(am_df_full['time_start'] == 0) & (am_df_full['time_end'] == time_end)]\n",
    "    apo_closed_slice_results_df = apo_df_full[(apo_df_full['time_start'] == 0) & (apo_df_full['time_end'] == time_end)]\n",
    "    nutlin_closed_slice_results_df = nutlin_df_full[(nutlin_df_full['time_start'] == 0) & (nutlin_df_full['time_end'] == time_end)]\n",
    "\n",
    "    \n",
    "    am_pred_ddg = am_open_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "    nutlin_pred_ddg = nutlin_closed_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "\n",
    "    am_pred_ddg_std = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "\n",
    "    # create separate dataframes for keeping track of time depedenent std and the mutant names\n",
    "    am_pred_ddg_std_timed = deepcopy(am_open_slice_results_df)\n",
    "    nutlin_pred_ddg_std_timed = deepcopy(nutlin_closed_slice_results_df)\n",
    "\n",
    "    am_pred_ddg_std_timed[\"ddg std. (kcal/mol)\"] = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std_timed[\"ddg std. (kcal/mol)\"] = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # drop dG avg. (kcal/mol) column\n",
    "    am_pred_ddg_std_timed.drop(columns=[\"dG avg. (kcal/mol)\"], inplace=True)\n",
    "    nutlin_pred_ddg_std_timed.drop(columns=[\"dG avg. (kcal/mol)\"], inplace=True)\n",
    "\n",
    "    temporal_am_pred_ddg_std.append(am_pred_ddg_std_timed)\n",
    "    temporal_nutlin_pred_ddg_std.append(nutlin_pred_ddg_std_timed)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_std, nutlin_pred_ddg_std\n",
    "\n",
    "    # rename columns\n",
    "    am_pred_ddg = am_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    am_pred_ddg_std = am_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "    nutlin_pred_ddg = nutlin_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    nutlin_pred_ddg_std = nutlin_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "\n",
    "    am_pred_ddg_df = pd.DataFrame(am_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    am_pred_ddg_std = pd.DataFrame(am_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_df = pd.DataFrame(nutlin_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_std = pd.DataFrame(nutlin_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "\n",
    "    # reindex the dataframes to match the experimental data\n",
    "    am_pred_ddg_df.reindex(am_exp_ddg_kcal_df.index)\n",
    "    am_pred_ddg_std.reindex(am_exp_ddg_kcal_df.index)\n",
    "\n",
    "    nutlin_pred_ddg_df.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "    nutlin_pred_ddg_std.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_df, nutlin_pred_ddg_df\n",
    "\n",
    "    predicted_ddg_df = pd.concat([am_pred_ddg_df, nutlin_pred_ddg_df])\n",
    "    predicted_ddg_std_df = pd.concat([am_pred_ddg_std, nutlin_pred_ddg_std])\n",
    "\n",
    "    experimental_ddg_df = pd.concat([am_exp_ddg_kcal_df, nutlin_exp_ddg_kcal_df])\n",
    "\n",
    "    # predicted_ddg_df, experimental_ddg_df\n",
    "\n",
    "    # to numpy array\n",
    "    predicted_ddg = predicted_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    predicted_ddg_std = predicted_ddg_std_df[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "    experimental_ddg = experimental_ddg_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "\n",
    "\n",
    "    # predicted_ddg, experimental_ddg\n",
    "\n",
    "    rmse_partial = calculate_rmse(predicted_ddg, experimental_ddg)\n",
    "    mae_partial = calculate_mae(predicted_ddg, experimental_ddg)\n",
    "\n",
    "    # rmse_partial, mae_partial\n",
    "\n",
    "    # convert to numpy arrays for plotting\n",
    "    am_exp_ddg_kcal_np = am_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_np = am_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_std_np = am_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    nutlin_exp_ddg_kcal_np = nutlin_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_np = nutlin_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_std_np = nutlin_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    temporal_rmse[f\"{time_start_ns}-{time_end_ns}\"] = rmse_partial\n",
    "    temporal_mae[f\"{time_start_ns}-{time_end_ns}\"] = mae_partial\n",
    "    temporal_std[f\"{time_start_ns}-{time_end_ns}\"] = predicted_ddg_std.mean()\n",
    "\n",
    "\n",
    "    ### PLOT OF Dominant Lid States\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(layout='tight')\n",
    "\n",
    "    x = np.arange(-5, 10, 1)\n",
    "    y = np.arange(-5, 10, 1)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    ax_x_lim, ax_y_lim = -2, 6\n",
    "    padding_x = 0.15\n",
    "\n",
    "\n",
    "\n",
    "    axs.fill_between(x, [i - 1 for i in y], [i + 1 for i in y], alpha=0.2, color='grey')\n",
    "    axs.fill_between(x, [i - 0.5 for i in y], [i + 0.5 for i in y], alpha=0.2, color='grey')\n",
    "    axs.errorbar(x=nutlin_exp_ddg_kcal_np, y=nutlin_pred_ddg_np, yerr=nutlin_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#6fc1dcff', ecolor='black', label='Nutlin-3a')\n",
    "    axs.errorbar(x=am_exp_ddg_kcal_np , y=am_pred_ddg_np, yerr=am_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#F07167', ecolor='black', label='AM-7209')\n",
    "    axs.legend(loc='upper left')\n",
    "    axs.set_ylim(ax_x_lim, ax_y_lim)\n",
    "    axs.set_xlim(ax_x_lim, ax_y_lim)\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.set_ylabel(\"Predicted $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_xlabel(\"Experimental $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_box_aspect(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    axs.annotate('V14G', (nutlin_exp_ddg_kcal_np[0], nutlin_pred_ddg_np[0]), size=12, xytext=(-45, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (nutlin_exp_ddg_kcal_np[1], nutlin_pred_ddg_np[1]), size=12, xytext=(15, -6), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (nutlin_exp_ddg_kcal_np[2], nutlin_pred_ddg_np[2]), size=12, xytext=(-45, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (nutlin_exp_ddg_kcal_np[3], nutlin_pred_ddg_np[3]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (nutlin_exp_ddg_kcal_np[4], nutlin_pred_ddg_np[4]), size=12, xytext=(-80, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.annotate('V14G', (am_exp_ddg_kcal_np [0], am_pred_ddg_np[0]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (am_exp_ddg_kcal_np [1], am_pred_ddg_np[1]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (am_exp_ddg_kcal_np [2], am_pred_ddg_np[2]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (am_exp_ddg_kcal_np [3], am_pred_ddg_np[3]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (am_exp_ddg_kcal_np [4], am_pred_ddg_np[4]), size=12, xytext=(15, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    # from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "    # axs.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    # axs.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    textstr1 = f\"RMSE:      {rmse_partial:.2f}     MAE:      {mae_partial:.2f}\\n\"\n",
    "    textstr = textstr1 \n",
    "    #title = r'MDM2 Dominant Lid States Only (BSS Inputs - Mixture of Replicas)'\n",
    "    title = f'MDM2 EQ. FEP Dominant State Lid Mutations (N = {len(experimental_ddg)})'\n",
    "    # bootstrap statistics\n",
    "    res_rmse = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='RMSE')\n",
    "    print(res_rmse)\n",
    "    res_mae = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='MUE')\n",
    "    res_rho = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='rho')\n",
    "\n",
    "    # append lower and upper bounds to the dictionary\n",
    "    temporal_rmse_lower[f\"{time_start_ns}-{time_end_ns}\"] = res_rmse['low']\n",
    "    temporal_rmse_upper[f\"{time_start_ns}-{time_end_ns}\"] = res_rmse['high']\n",
    "\n",
    "\n",
    "    textstr = f\"RMSE:        {res_rmse['mle']:.2f} [95%: {res_rmse['low']:.2f}, {res_rmse['high']:.2f}]\\nMAE:        {res_mae['mle']:.2f} [95%: {res_mae['low']:.2f}, {res_mae['high']:.2f}]\\n\"\n",
    "    full_title = f\"{textstr} {title}\"\n",
    "    axs.set_title(full_title, family=\"monospace\", loc='right')\n",
    "    fig.set_size_inches(10,10)\n",
    "    # plt.savefig(f'paper_eq_fep_plots/{time_start_ns}-{time_end_ns}ns.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee18276c",
   "metadata": {},
   "source": [
    "## EQ 100 to 10 % (Forward Discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c2080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_df_reverse_full = pd.read_csv('eq_fep_analysed_results_100_to_10/am_df_full.csv')\n",
    "apo_df_reverse_full = pd.read_csv('eq_fep_analysed_results_100_to_10/apo_df_full.csv')\n",
    "nutlin_df_reverse_full = pd.read_csv('eq_fep_analysed_results_100_to_10/nutlin_df_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0d3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_df_reverse_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5c9a06",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621d56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "\n",
    "\n",
    "temporal_rmse = {}\n",
    "temporal_rmse_lower = {}\n",
    "temporal_rmse_upper = {}\n",
    "temporal_mae = {}\n",
    "temporal_std = {}\n",
    "temporal_am_pred_ddg_std = []\n",
    "temporal_nutlin_pred_ddg_std = []\n",
    "\n",
    "time_end_ns = 100 # ns\n",
    "\n",
    "for time_start_ns in range(10, 100, 10):\n",
    "    time_start = time_start_ns * 1000 # ns to ps\n",
    "\n",
    "    # need to use the pandas query method to filter the dataframes because saving to csv did not save the multiindex\n",
    "    am_open_slice_results_df = am_df_reverse_full[(am_df_reverse_full['time_start'] == time_start) & (am_df_reverse_full['time_end'] == 100000)]\n",
    "    apo_closed_slice_results_df = apo_df_reverse_full[(apo_df_reverse_full['time_start'] == time_start) & (apo_df_reverse_full['time_end'] == 100000)]\n",
    "    nutlin_closed_slice_results_df = nutlin_df_reverse_full[(nutlin_df_reverse_full['time_start'] == time_start) & (nutlin_df_reverse_full['time_end'] == 100000)]\n",
    "\n",
    "    \n",
    "    time_end = time_end_ns * 1000 # ns to ps\n",
    "    am_pred_ddg = am_open_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "    nutlin_pred_ddg = nutlin_closed_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "\n",
    "    am_pred_ddg_std = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # create separate dataframes for keeping track of time depedenent std and the mutant names\n",
    "    am_pred_ddg_std_timed = deepcopy(am_open_slice_results_df)\n",
    "    nutlin_pred_ddg_std_timed = deepcopy(nutlin_closed_slice_results_df)\n",
    "\n",
    "    am_pred_ddg_std_timed[\"ddg std. (kcal/mol)\"] = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std_timed[\"ddg std. (kcal/mol)\"] = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # drop dG avg. (kcal/mol) column\n",
    "    am_pred_ddg_std_timed.drop(columns=[\"dG avg. (kcal/mol)\"], inplace=True)\n",
    "    nutlin_pred_ddg_std_timed.drop(columns=[\"dG avg. (kcal/mol)\"], inplace=True)\n",
    "\n",
    "    temporal_am_pred_ddg_std.append(am_pred_ddg_std_timed)\n",
    "    temporal_nutlin_pred_ddg_std.append(nutlin_pred_ddg_std_timed)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_std, nutlin_pred_ddg_std\n",
    "\n",
    "    # rename columns\n",
    "    am_pred_ddg = am_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    am_pred_ddg_std = am_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "    nutlin_pred_ddg = nutlin_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    nutlin_pred_ddg_std = nutlin_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "\n",
    "    am_pred_ddg_df = pd.DataFrame(am_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    am_pred_ddg_std = pd.DataFrame(am_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_df = pd.DataFrame(nutlin_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_std = pd.DataFrame(nutlin_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "\n",
    "    # reindex the dataframes to match the experimental data\n",
    "    am_pred_ddg_df.reindex(am_exp_ddg_kcal_df.index)\n",
    "    am_pred_ddg_std.reindex(am_exp_ddg_kcal_df.index)\n",
    "\n",
    "    print(am_pred_ddg_df, am_pred_ddg_std)\n",
    "\n",
    "    nutlin_pred_ddg_df.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "    nutlin_pred_ddg_std.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_df, nutlin_pred_ddg_df\n",
    "\n",
    "    predicted_ddg_df = pd.concat([am_pred_ddg_df, nutlin_pred_ddg_df])\n",
    "    predicted_ddg_std_df = pd.concat([am_pred_ddg_std, nutlin_pred_ddg_std])\n",
    "\n",
    "    experimental_ddg_df = pd.concat([am_exp_ddg_kcal_df, nutlin_exp_ddg_kcal_df])\n",
    "\n",
    "    # predicted_ddg_df, experimental_ddg_df\n",
    "\n",
    "    # to numpy array\n",
    "    predicted_ddg = predicted_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    predicted_ddg_std = predicted_ddg_std_df[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "    experimental_ddg = experimental_ddg_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "\n",
    "\n",
    "    # predicted_ddg, experimental_ddg\n",
    "\n",
    "    rmse_partial = calculate_rmse(predicted_ddg, experimental_ddg)\n",
    "    mae_partial = calculate_mae(predicted_ddg, experimental_ddg)\n",
    "\n",
    "    # rmse_partial, mae_partial\n",
    "\n",
    "    # convert to numpy arrays for plotting\n",
    "    am_exp_ddg_kcal_np = am_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_np = am_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_std_np = am_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    nutlin_exp_ddg_kcal_np = nutlin_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_np = nutlin_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_std_np = nutlin_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    temporal_rmse[f\"{time_start_ns}-{time_end_ns}\"] = rmse_partial\n",
    "    temporal_mae[f\"{time_start_ns}-{time_end_ns}\"] = mae_partial\n",
    "    temporal_std[f\"{time_start_ns}-{time_end_ns}\"] = predicted_ddg_std.mean()\n",
    "\n",
    "\n",
    "    ### PLOT OF Dominant Lid States\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(layout='tight')\n",
    "\n",
    "    x = np.arange(-5, 10, 1)\n",
    "    y = np.arange(-5, 10, 1)\n",
    "    # plt.rcParams.update({'font.size': 14})\n",
    "    ax_x_lim, ax_y_lim = -2, 6\n",
    "    padding_x = 0.15\n",
    "\n",
    "\n",
    "\n",
    "    axs.fill_between(x, [i - 1 for i in y], [i + 1 for i in y], alpha=0.2, color='grey')\n",
    "    axs.fill_between(x, [i - 0.5 for i in y], [i + 0.5 for i in y], alpha=0.2, color='grey')\n",
    "    axs.errorbar(x=nutlin_exp_ddg_kcal_np, y=nutlin_pred_ddg_np, yerr=nutlin_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#6fc1dcff', ecolor='black', label='Nutlin-3a')\n",
    "    axs.errorbar(x=am_exp_ddg_kcal_np , y=am_pred_ddg_np, yerr=am_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#F07167', ecolor='black', label='AM-7209')\n",
    "    axs.legend(loc='upper left')\n",
    "    axs.set_ylim(ax_x_lim, ax_y_lim)\n",
    "    axs.set_xlim(ax_x_lim, ax_y_lim)\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.set_ylabel(\"Predicted $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_xlabel(\"Experimental $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_box_aspect(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    axs.annotate('V14G', (nutlin_exp_ddg_kcal_np[0], nutlin_pred_ddg_np[0]), size=18, xytext=(-55, -8), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (nutlin_exp_ddg_kcal_np[1], nutlin_pred_ddg_np[1]), size=18, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (nutlin_exp_ddg_kcal_np[2], nutlin_pred_ddg_np[2]), size=18, xytext=(-55, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (nutlin_exp_ddg_kcal_np[3], nutlin_pred_ddg_np[3]), size=18, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (nutlin_exp_ddg_kcal_np[4], nutlin_pred_ddg_np[4]), size=18, xytext=(-100, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.annotate('V14G', (am_exp_ddg_kcal_np [0], am_pred_ddg_np[0]), size=18, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (am_exp_ddg_kcal_np [1], am_pred_ddg_np[1]), size=18, xytext=(-55, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (am_exp_ddg_kcal_np [2], am_pred_ddg_np[2]), size=18, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (am_exp_ddg_kcal_np [3], am_pred_ddg_np[3]), size=18, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (am_exp_ddg_kcal_np [4], am_pred_ddg_np[4]), size=18, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    textstr1 = f\"RMSE:      {rmse_partial:.2f}     MAE:      {mae_partial:.2f}\\n\"\n",
    "    textstr = textstr1 \n",
    "    # bootstrap statistics\n",
    "    res_rmse = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='RMSE')\n",
    "    res_mae = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='MUE')\n",
    "    res_rho = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='rho')\n",
    "    res_r2 = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='R2')\n",
    "    res_ktau = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='KTAU')\n",
    "    print(res_rmse)\n",
    "\n",
    "    # append lower and upper bounds to the dictionary\n",
    "    temporal_rmse_lower[f\"{time_start_ns}-{time_end_ns}\"] = res_rmse['low']\n",
    "    temporal_rmse_upper[f\"{time_start_ns}-{time_end_ns}\"] = res_rmse['high']\n",
    "\n",
    "    textstr = f\"RMSE:        {res_rmse['mle']:.2f} [95%: {res_rmse['low']:.2f}, {res_rmse['high']:.2f}]\\nMAE:        {res_mae['mle']:.2f} [95%: {res_mae['low']:.2f}, {res_mae['high']:.2f}]\\n rho:        {res_rho['mle']:.2f} [95%: {res_rho['low']:.2f}, {res_rho['high']:.2f}]\\n R2:        {res_r2['mle']:.2f} [95%: {res_r2['low']:.2f}, {res_r2['high']:.2f}]\\nKTAU:        {res_ktau['mle']:.2f} [95%: {res_ktau['low']:.2f}, {res_ktau['high']:.2f}]\"\n",
    "\n",
    "    # full_title = f\"{textstr} {title}\"\n",
    "    full_title = f\"{textstr}\"\n",
    "    axs.set_title(full_title, family=\"monospace\", loc='right')\n",
    "    fig.set_size_inches(10,10)\n",
    "    #plt.savefig(f'paper_eq_fep_plots/{time_start_ns}-{time_end_ns}ns_ff14sb.pdf', dpi=600, bbox_inches='tight')\n",
    "    #plt.savefig(f'paper_eq_fep_plots/{time_start_ns}-{time_end_ns}ns_ff14sb.png', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0bd85",
   "metadata": {},
   "source": [
    "## NEQ 0 to 100 % (Forward Convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4096c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_neq_full_results_df = pd.read_csv('neq_fep_analysed_results_0_to_100/am_df_full.csv')\n",
    "apo_neq_full_results_df = pd.read_csv('neq_fep_analysed_results_0_to_100/apo_df_full.csv')\n",
    "nutlin_neq_full_results_df = pd.read_csv('neq_fep_analysed_results_0_to_100/nutlin_df_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3673e",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_rmse = {}\n",
    "temporal_rmse_lower = {}\n",
    "temporal_rmse_upper = {}\n",
    "temporal_mae = {}\n",
    "temporal_std = {}\n",
    "temporal_am_pred_ddg_std = []\n",
    "temporal_nutlin_pred_ddg_std = []\n",
    "\n",
    "\n",
    "time_start_perc = 0 # ns\n",
    "\n",
    "for time_end_perc in range(10, 110, 10):\n",
    "\n",
    "    am_open_slice_results_df = am_neq_full_results_df[(am_neq_full_results_df['time_start_perc'] == 0) & (am_neq_full_results_df['time_end_perc'] == time_end_perc)]\n",
    "    apo_closed_slice_results_df = apo_neq_full_results_df[(apo_neq_full_results_df['time_start_perc'] == 0) & (apo_neq_full_results_df['time_end_perc'] == time_end_perc)]\n",
    "    nutlin_closed_slice_results_df = nutlin_neq_full_results_df[(nutlin_neq_full_results_df['time_start_perc'] == 0) & (nutlin_neq_full_results_df['time_end_perc'] == time_end_perc)]\n",
    "\n",
    "    \n",
    "    am_pred_ddg = am_open_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "    nutlin_pred_ddg = nutlin_closed_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "\n",
    "    am_pred_ddg_std = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "\n",
    "    # create separate dataframes for keeping track of time depedenent std and the mutant names\n",
    "    am_pred_ddg_std_timed = deepcopy(am_open_slice_results_df)\n",
    "    nutlin_pred_ddg_std_timed = deepcopy(nutlin_closed_slice_results_df)\n",
    "\n",
    "    am_pred_ddg_std_timed[\"ddg std. (kcal/mol)\"] = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std_timed[\"ddg std. (kcal/mol)\"] = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # drop dG avg. (kcal/mol) column\n",
    "    am_pred_ddg_std_timed.drop(columns=[\"dG avg. (kcal/mol)\"], inplace=True)\n",
    "    nutlin_pred_ddg_std_timed.drop(columns=[\"dG avg. (kcal/mol)\"], inplace=True)\n",
    "\n",
    "    temporal_am_pred_ddg_std.append(am_pred_ddg_std_timed)\n",
    "    temporal_nutlin_pred_ddg_std.append(nutlin_pred_ddg_std_timed)\n",
    "\n",
    "    # am_pred_ddg_std, nutlin_pred_ddg_std\n",
    "\n",
    "    # rename columns\n",
    "    am_pred_ddg = am_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    am_pred_ddg_std = am_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "    nutlin_pred_ddg = nutlin_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    nutlin_pred_ddg_std = nutlin_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "\n",
    "    am_pred_ddg_df = pd.DataFrame(am_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    am_pred_ddg_std = pd.DataFrame(am_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_df = pd.DataFrame(nutlin_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_std = pd.DataFrame(nutlin_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "\n",
    "    # reindex the dataframes to match the experimental data\n",
    "    am_pred_ddg_df.reindex(am_exp_ddg_kcal_df.index)\n",
    "    am_pred_ddg_std.reindex(am_exp_ddg_kcal_df.index)\n",
    "\n",
    "    nutlin_pred_ddg_df.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "    nutlin_pred_ddg_std.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_df, nutlin_pred_ddg_df\n",
    "\n",
    "    predicted_ddg_df = pd.concat([am_pred_ddg_df, nutlin_pred_ddg_df])\n",
    "    predicted_ddg_std_df = pd.concat([am_pred_ddg_std, nutlin_pred_ddg_std])\n",
    "\n",
    "    experimental_ddg_df = pd.concat([am_exp_ddg_kcal_df, nutlin_exp_ddg_kcal_df])\n",
    "\n",
    "    # predicted_ddg_df, experimental_ddg_df\n",
    "\n",
    "    # to numpy array\n",
    "    predicted_ddg = predicted_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    predicted_ddg_std = predicted_ddg_std_df[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "    experimental_ddg = experimental_ddg_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "\n",
    "\n",
    "    # predicted_ddg, experimental_ddg\n",
    "\n",
    "    rmse_partial = calculate_rmse(predicted_ddg, experimental_ddg)\n",
    "    mae_partial = calculate_mae(predicted_ddg, experimental_ddg)\n",
    "\n",
    "    # rmse_partial, mae_partial\n",
    "\n",
    "    # convert to numpy arrays for plotting\n",
    "    am_exp_ddg_kcal_np = am_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_np = am_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_std_np = am_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    nutlin_exp_ddg_kcal_np = nutlin_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_np = nutlin_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_std_np = nutlin_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    temporal_rmse[f\"{time_start_perc}-{time_end_perc}\"] = rmse_partial\n",
    "    temporal_mae[f\"{time_start_perc}-{time_end_perc}\"] = mae_partial\n",
    "    temporal_std[f\"{time_start_perc}-{time_end_perc}\"] = predicted_ddg_std.mean()\n",
    "\n",
    "\n",
    "    ### PLOT OF Dominant Lid States\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(layout='tight')\n",
    "\n",
    "    x = np.arange(-5, 10, 1)\n",
    "    y = np.arange(-5, 10, 1)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    ax_x_lim, ax_y_lim = -2, 6\n",
    "    padding_x = 0.15\n",
    "\n",
    "\n",
    "\n",
    "    axs.fill_between(x, [i - 1 for i in y], [i + 1 for i in y], alpha=0.2, color='grey')\n",
    "    axs.fill_between(x, [i - 0.5 for i in y], [i + 0.5 for i in y], alpha=0.2, color='grey')\n",
    "    axs.errorbar(x=nutlin_exp_ddg_kcal_np, y=nutlin_pred_ddg_np, yerr=nutlin_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#6fc1dcff', ecolor='black', label='Nutlin-3a')\n",
    "    axs.errorbar(x=am_exp_ddg_kcal_np , y=am_pred_ddg_np, yerr=am_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#F07167', ecolor='black', label='AM-7209')\n",
    "    axs.legend(loc='upper left')\n",
    "    axs.set_ylim(ax_x_lim, ax_y_lim)\n",
    "    axs.set_xlim(ax_x_lim, ax_y_lim)\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.set_ylabel(\"Predicted $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_xlabel(\"Experimental $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_box_aspect(1)\n",
    "\n",
    "\n",
    "\n",
    "    axs.annotate('V14G', (nutlin_exp_ddg_kcal_np[0], nutlin_pred_ddg_np[0]), size=12, xytext=(-45, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (nutlin_exp_ddg_kcal_np[1], nutlin_pred_ddg_np[1]), size=12, xytext=(15, -6), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (nutlin_exp_ddg_kcal_np[2], nutlin_pred_ddg_np[2]), size=12, xytext=(-45, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (nutlin_exp_ddg_kcal_np[3], nutlin_pred_ddg_np[3]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (nutlin_exp_ddg_kcal_np[4], nutlin_pred_ddg_np[4]), size=12, xytext=(-80, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.annotate('V14G', (am_exp_ddg_kcal_np [0], am_pred_ddg_np[0]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (am_exp_ddg_kcal_np [1], am_pred_ddg_np[1]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (am_exp_ddg_kcal_np [2], am_pred_ddg_np[2]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (am_exp_ddg_kcal_np [3], am_pred_ddg_np[3]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (am_exp_ddg_kcal_np [4], am_pred_ddg_np[4]), size=12, xytext=(15, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    # from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "    # axs.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    # axs.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    textstr1 = f\"RMSE:      {rmse_partial:.2f}     MAE:      {mae_partial:.2f}\\n\"\n",
    "    textstr = textstr1 \n",
    "    #title = r'MDM2 Dominant Lid States Only (BSS Inputs - Mixture of Replicas)'\n",
    "    title = f'MDM2 NEQ. FEP Dominant State Lid Mutations (N = {len(experimental_ddg)})'\n",
    "    # bootstrap statistics\n",
    "    res_rmse = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='RMSE')\n",
    "    print(res_rmse)\n",
    "    res_mae = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='MUE')\n",
    "    res_rho = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='rho')\n",
    "\n",
    "    # append lower and upper bounds to the dictionary\n",
    "    temporal_rmse_lower[f\"{time_start_perc}-{time_end_perc}\"] = res_rmse['low']\n",
    "    temporal_rmse_upper[f\"{time_start_perc}-{time_end_perc}\"] = res_rmse['high']\n",
    "\n",
    "\n",
    "    textstr = f\"RMSE:        {res_rmse['mle']:.2f} [95%: {res_rmse['low']:.2f}, {res_rmse['high']:.2f}]\\nMAE:        {res_mae['mle']:.2f} [95%: {res_mae['low']:.2f}, {res_mae['high']:.2f}]\\n\"\n",
    "    full_title = f\"{textstr} {title}\"\n",
    "    axs.set_title(full_title, family=\"monospace\", loc='right')\n",
    "    fig.set_size_inches(10,10)\n",
    "    # plt.savefig(f'paper_neq_fep_plots/{time_start_perc}-{time_end_perc}_perc.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8229c8",
   "metadata": {},
   "source": [
    "## NEQ 100 to 10 % (Forward Discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddbc43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_neq_full_results_df = pd.read_csv('neq_fep_analysed_results_100_to_10/am_df_full.csv')\n",
    "apo_neq_full_results_df = pd.read_csv('neq_fep_analysed_results_100_to_10/apo_df_full.csv')\n",
    "nutlin_neq_full_results_df = pd.read_csv('neq_fep_analysed_results_100_to_10/nutlin_df_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc82780",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c94ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_rmse = {}\n",
    "temporal_rmse_lower = {}\n",
    "temporal_rmse_upper = {}\n",
    "temporal_mae = {}\n",
    "temporal_std = {}\n",
    "temporal_am_pred_ddg_std = []\n",
    "temporal_nutlin_pred_ddg_std = []\n",
    "\n",
    "time_end_perc = 100\n",
    "\n",
    "for time_start_perc in range(10, 100, 10):\n",
    "\n",
    "\n",
    "    am_open_slice_results_df = am_neq_full_results_df[(am_neq_full_results_df['time_start_perc'] == time_start_perc) & (am_neq_full_results_df['time_end_perc'] == 100)]\n",
    "    apo_closed_slice_results_df = apo_neq_full_results_df[(apo_neq_full_results_df['time_start_perc'] == time_start_perc) & (apo_neq_full_results_df['time_end_perc'] == 100)]\n",
    "    nutlin_closed_slice_results_df = nutlin_neq_full_results_df[(nutlin_neq_full_results_df['time_start_perc'] == time_start_perc) & (nutlin_neq_full_results_df['time_end_perc'] == 100)]\n",
    "\n",
    "    \n",
    "    am_pred_ddg = am_open_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "    nutlin_pred_ddg = nutlin_closed_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "\n",
    "    am_pred_ddg_std = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # create separate dataframes for keeping track of time depedenent std and the mutant names\n",
    "    am_pred_ddg_std_timed = deepcopy(am_open_slice_results_df)\n",
    "    nutlin_pred_ddg_std_timed = deepcopy(nutlin_closed_slice_results_df)\n",
    "\n",
    "    am_pred_ddg_std_timed[\"ddg std. (kcal/mol)\"] = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std_timed[\"ddg std. (kcal/mol)\"] = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # drop dG avg. (kcal/mol) column\n",
    "    am_pred_ddg_std_timed.drop(columns=[\"dG avg. (kcal/mol)\"], inplace=True)\n",
    "    nutlin_pred_ddg_std_timed.drop(columns=[\"dG avg. (kcal/mol)\"], inplace=True)\n",
    "\n",
    "    temporal_am_pred_ddg_std.append(am_pred_ddg_std_timed)\n",
    "    temporal_nutlin_pred_ddg_std.append(nutlin_pred_ddg_std_timed)\n",
    "\n",
    "    # am_pred_ddg_std, nutlin_pred_ddg_std\n",
    "\n",
    "    # rename columns\n",
    "    am_pred_ddg = am_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    am_pred_ddg_std = am_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "    nutlin_pred_ddg = nutlin_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    nutlin_pred_ddg_std = nutlin_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "\n",
    "    am_pred_ddg_df = pd.DataFrame(am_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    am_pred_ddg_std = pd.DataFrame(am_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_df = pd.DataFrame(nutlin_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_std = pd.DataFrame(nutlin_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "\n",
    "    # reindex the dataframes to match the experimental data\n",
    "    am_pred_ddg_df.reindex(am_exp_ddg_kcal_df.index)\n",
    "    am_pred_ddg_std.reindex(am_exp_ddg_kcal_df.index)\n",
    "\n",
    "    nutlin_pred_ddg_df.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "    nutlin_pred_ddg_std.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_df, nutlin_pred_ddg_df\n",
    "\n",
    "    predicted_ddg_df = pd.concat([am_pred_ddg_df, nutlin_pred_ddg_df])\n",
    "    predicted_ddg_std_df = pd.concat([am_pred_ddg_std, nutlin_pred_ddg_std])\n",
    "\n",
    "    experimental_ddg_df = pd.concat([am_exp_ddg_kcal_df, nutlin_exp_ddg_kcal_df])\n",
    "\n",
    "    # predicted_ddg_df, experimental_ddg_df\n",
    "\n",
    "    # to numpy array\n",
    "    predicted_ddg = predicted_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    predicted_ddg_std = predicted_ddg_std_df[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "    experimental_ddg = experimental_ddg_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "\n",
    "\n",
    "    # predicted_ddg, experimental_ddg\n",
    "\n",
    "    rmse_partial = calculate_rmse(predicted_ddg, experimental_ddg)\n",
    "    mae_partial = calculate_mae(predicted_ddg, experimental_ddg)\n",
    "\n",
    "    # rmse_partial, mae_partial\n",
    "\n",
    "    # convert to numpy arrays for plotting\n",
    "    am_exp_ddg_kcal_np = am_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_np = am_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_std_np = am_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    nutlin_exp_ddg_kcal_np = nutlin_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_np = nutlin_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_std_np = nutlin_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    temporal_rmse[f\"{time_start_perc}-{time_end_perc}\"] = rmse_partial\n",
    "    temporal_mae[f\"{time_start_perc}-{time_end_perc}\"] = mae_partial\n",
    "    temporal_std[f\"{time_start_perc}-{time_end_perc}\"] = predicted_ddg_std.mean()\n",
    "\n",
    "\n",
    "    ### PLOT OF Dominant Lid States\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(layout='tight')\n",
    "\n",
    "    x = np.arange(-5, 10, 1)\n",
    "    y = np.arange(-5, 10, 1)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    ax_x_lim, ax_y_lim = -2, 6\n",
    "    padding_x = 0.15\n",
    "\n",
    "\n",
    "\n",
    "    axs.fill_between(x, [i - 1 for i in y], [i + 1 for i in y], alpha=0.2, color='grey')\n",
    "    axs.fill_between(x, [i - 0.5 for i in y], [i + 0.5 for i in y], alpha=0.2, color='grey')\n",
    "    axs.errorbar(x=nutlin_exp_ddg_kcal_np, y=nutlin_pred_ddg_np, yerr=nutlin_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#6fc1dcff', ecolor='black', label='Nutlin-3a')\n",
    "    axs.errorbar(x=am_exp_ddg_kcal_np , y=am_pred_ddg_np, yerr=am_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#F07167', ecolor='black', label='AM-7209')\n",
    "    axs.legend(loc='upper left')\n",
    "    axs.set_ylim(ax_x_lim, ax_y_lim)\n",
    "    axs.set_xlim(ax_x_lim, ax_y_lim)\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.set_ylabel(\"Predicted $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_xlabel(\"Experimental $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_box_aspect(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    axs.annotate('V14G', (nutlin_exp_ddg_kcal_np[0], nutlin_pred_ddg_np[0]), size=12, xytext=(-45, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (nutlin_exp_ddg_kcal_np[1], nutlin_pred_ddg_np[1]), size=12, xytext=(15, -6), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (nutlin_exp_ddg_kcal_np[2], nutlin_pred_ddg_np[2]), size=12, xytext=(-45, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (nutlin_exp_ddg_kcal_np[3], nutlin_pred_ddg_np[3]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (nutlin_exp_ddg_kcal_np[4], nutlin_pred_ddg_np[4]), size=12, xytext=(-80, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.annotate('V14G', (am_exp_ddg_kcal_np [0], am_pred_ddg_np[0]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (am_exp_ddg_kcal_np [1], am_pred_ddg_np[1]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (am_exp_ddg_kcal_np [2], am_pred_ddg_np[2]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (am_exp_ddg_kcal_np [3], am_pred_ddg_np[3]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (am_exp_ddg_kcal_np [4], am_pred_ddg_np[4]), size=12, xytext=(15, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    # from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "    # axs.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    # axs.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    textstr1 = f\"RMSE:      {rmse_partial:.2f}     MAE:      {mae_partial:.2f}\\n\"\n",
    "    textstr = textstr1 \n",
    "    #title = r'MDM2 Dominant Lid States Only (BSS Inputs - Mixture of Replicas)'\n",
    "    title = f'MDM2 NEQ. FEP Dominant State Lid Mutations (N = {len(experimental_ddg)})'\n",
    "    # bootstrap statistics\n",
    "    res_rmse = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='RMSE')\n",
    "    print(res_rmse)\n",
    "    res_mae = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='MUE')\n",
    "    res_rho = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='rho')\n",
    "\n",
    "    # append lower and upper bounds to the dictionary\n",
    "    temporal_rmse_lower[f\"{time_start_perc}-{time_end_perc}\"] = res_rmse['low']\n",
    "    temporal_rmse_upper[f\"{time_start_perc}-{time_end_perc}\"] = res_rmse['high']\n",
    "\n",
    "\n",
    "    textstr = f\"RMSE:        {res_rmse['mle']:.2f} [95%: {res_rmse['low']:.2f}, {res_rmse['high']:.2f}]\\nMAE:        {res_mae['mle']:.2f} [95%: {res_mae['low']:.2f}, {res_mae['high']:.2f}]\\n\"\n",
    "    full_title = f\"{textstr} {title}\"\n",
    "    axs.set_title(full_title, family=\"monospace\", loc='right')\n",
    "    fig.set_size_inches(10,10)\n",
    "    # plt.savefig(f'paper_neq_fep_plots/{time_start_perc}-{time_end_perc}_perc.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2aeb80",
   "metadata": {},
   "source": [
    "## NEQ Pooled 0 to 100 % (Forward Convergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e12e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutants = [\"v14g\", \"t16g\", \"q18g\", \"i19g\", \"t16g_i19g\"]\n",
    "am_neq_full_results_pooled_df = pd.DataFrame()\n",
    "apo_neq_full_results_pooled_df = pd.DataFrame()\n",
    "nutlin_neq_full_results_pooled_df = pd.DataFrame()\n",
    "\n",
    "for mutant in mutants:\n",
    "\n",
    "    time_start = 0\n",
    "    time_end_slice = [275, 550, 825, 1100, 1375, 1650, 1925, 2200, 2475, 2750]\n",
    "\n",
    "    for time_end in time_end_slice:\n",
    "\n",
    "        am_open_pooled_df = pd.read_csv(f\"neq_xvg_analysis/am_open/system_pooled_results/results_0_{time_end}.dat\",\n",
    "                                names=[\"mutant\", \"dG (kcal/mol)\"])\n",
    "\n",
    "        # Define the string to search for\n",
    "        search_string = rf'\\b{mutant}\\b'\n",
    "\n",
    "        # Apply the string containment check across all elements\n",
    "        contains_string = am_open_pooled_df.applymap(lambda x: specific_pattern_match(x, search_string))\n",
    "\n",
    "        # Filter the DataFrame to get only the rows where any element contains the string\n",
    "        filtered_pooled_df = am_open_pooled_df[contains_string.any(axis=1)]\n",
    "\n",
    "        # Use a regular expression to extract floating point values\n",
    "        # The regex pattern r'([-+]?\\d*\\.\\d+|\\d+)' matches both integers and floating point numbers\n",
    "        filtered_pooled_df['extracted dG (kcal/mol)'] = filtered_pooled_df[\"dG (kcal/mol)\"].str.extract(r'([-+]?\\d*\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "        if len(filtered_pooled_df['extracted dG (kcal/mol)']) != 1 or filtered_pooled_df['extracted dG (kcal/mol)'].isnull().sum() > 0:\n",
    "            raise ValueError(\"The number of extracted values is not equal to 1\")\n",
    "\n",
    "        # Display the DataFrame with the extracted values\n",
    "        # mean_dg = filtered_pooled_df['extracted dG (kcal/mol)'].mean()\n",
    "        # std_dg = filtered_pooled_df['extracted dG (kcal/mol)'].std()\n",
    "        pooled_dg = filtered_pooled_df['extracted dG (kcal/mol)'].tolist()\n",
    "        time_end_perc = time_end / time_end_slice[-1] * 100\n",
    "        processed_pooled_df = pd.DataFrame.from_dict({\"mutant\": mutant, \"dG pooled (kcal/mol)\": pooled_dg[0], \"time_start_perc\": time_start, \"time_end_perc\": time_end_perc}, orient=\"index\").T\n",
    "        am_neq_full_results_pooled_df = pd.concat([am_neq_full_results_pooled_df, processed_pooled_df])\n",
    "        am_neq_full_results_pooled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "for mutant in mutants:\n",
    "\n",
    "    time_start = 0\n",
    "    # if mutant == \"t16g_i19g\":\n",
    "    #     time_end_slice= [525, 1050, 1575, 2100, 2625, 3150, 3675, 4200, 4725, 5250]\n",
    "    # else:\n",
    "    time_end_slice = [275, 550, 825, 1100, 1375, 1650, 1925, 2200, 2475, 2750]\n",
    "\n",
    "\n",
    "    for time_end in time_end_slice:\n",
    "\n",
    "        apo_closed_pooled_df = pd.read_csv(f\"neq_xvg_analysis/apo_closed/system_pooled_results/results_0_{time_end}.dat\",\n",
    "                                names=[\"mutant\", \"dG (kcal/mol)\"])\n",
    "\n",
    "        # Define the string to search for\n",
    "        search_string = rf'\\b{mutant}\\b'\n",
    "\n",
    "        # Apply the string containment check across all elements\n",
    "        contains_string = apo_closed_pooled_df.applymap(lambda x: specific_pattern_match(x, search_string))\n",
    "\n",
    "        # Filter the DataFrame to get only the rows where any element contains the string\n",
    "        filtered_pooled_df = apo_closed_pooled_df[contains_string.any(axis=1)]\n",
    "\n",
    "        # Use a regular expression to extract floating point values\n",
    "        # The regex pattern r'([-+]?\\d*\\.\\d+|\\d+)' matches both integers and floating point numbers\n",
    "        filtered_pooled_df['extracted dG (kcal/mol)'] = filtered_pooled_df[\"dG (kcal/mol)\"].str.extract(r'([-+]?\\d*\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "        if len(filtered_pooled_df['extracted dG (kcal/mol)']) != 1 or filtered_pooled_df['extracted dG (kcal/mol)'].isnull().sum() > 0:\n",
    "            raise ValueError(\"The number of extracted values is not equal to 1\")\n",
    "\n",
    "        # Display the DataFrame with the extracted values\n",
    "        # mean_dg = filtered_pooled_df['extracted dG (kcal/mol)'].mean()\n",
    "        # std_dg = filtered_pooled_df['extracted dG (kcal/mol)'].std()\n",
    "        time_end_perc = time_end / time_end_slice[-1] * 100\n",
    "        pooled_dg = filtered_pooled_df['extracted dG (kcal/mol)'].tolist()\n",
    "        processed_pooled_df = pd.DataFrame.from_dict({\"mutant\": mutant, \"dG pooled (kcal/mol)\": pooled_dg[0], \"time_start_perc\": time_start, \"time_end_perc\": time_end_perc}, orient=\"index\").T\n",
    "        apo_neq_full_results_pooled_df = pd.concat([apo_neq_full_results_pooled_df, processed_pooled_df])\n",
    "        apo_neq_full_results_pooled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "for mutant in mutants:\n",
    "\n",
    "    time_start = 0\n",
    "    time_end_slice = [275, 550, 825, 1100, 1375, 1650, 1925, 2200, 2475, 2750]\n",
    "\n",
    "    for time_end in time_end_slice:\n",
    "\n",
    "        nutlin_closed_pooled_df = pd.read_csv(f\"neq_xvg_analysis/nutlin_closed/system_pooled_results/results_0_{time_end}.dat\",\n",
    "                                names=[\"mutant\", \"dG (kcal/mol)\"])\n",
    "\n",
    "        # Define the string to search for\n",
    "        search_string = rf'\\b{mutant}\\b'\n",
    "\n",
    "        # Apply the string containment check across all elements\n",
    "        contains_string = nutlin_closed_pooled_df.applymap(lambda x: specific_pattern_match(x, search_string))\n",
    "\n",
    "        # Filter the DataFrame to get only the rows where any element contains the string\n",
    "        filtered_pooled_df = nutlin_closed_pooled_df[contains_string.any(axis=1)]\n",
    "\n",
    "        # Use a regular expression to extract floating point values\n",
    "        # The regex pattern r'([-+]?\\d*\\.\\d+|\\d+)' matches both integers and floating point numbers\n",
    "        filtered_pooled_df['extracted dG (kcal/mol)'] = filtered_pooled_df[\"dG (kcal/mol)\"].str.extract(r'([-+]?\\d*\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "        if len(filtered_pooled_df['extracted dG (kcal/mol)']) != 1 or filtered_pooled_df['extracted dG (kcal/mol)'].isnull().sum() > 0:\n",
    "            raise ValueError(\"The number of extracted values is not equal to 1\")\n",
    "\n",
    "        # Display the DataFrame with the extracted values\n",
    "        # mean_dg = filtered_pooled_df['extracted dG (kcal/mol)'].mean()\n",
    "        # std_dg = filtered_pooled_df['extracted dG (kcal/mol)'].std()\n",
    "        time_end_perc = time_end / time_end_slice[-1] * 100\n",
    "        pooled_dg = filtered_pooled_df['extracted dG (kcal/mol)'].tolist()\n",
    "        processed_pooled_df = pd.DataFrame.from_dict({\"mutant\": mutant, \"dG pooled (kcal/mol)\": pooled_dg[0], \"time_start_perc\": time_start, \"time_end_perc\": time_end_perc}, orient=\"index\").T\n",
    "        nutlin_neq_full_results_pooled_df = pd.concat([nutlin_neq_full_results_pooled_df, processed_pooled_df])\n",
    "        nutlin_neq_full_results_pooled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# convert dtypes to float\n",
    "am_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"] = am_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"].astype(float)\n",
    "\n",
    "apo_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"] = apo_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"].astype(float)\n",
    "\n",
    "nutlin_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"] = nutlin_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"].astype(float)\n",
    "\n",
    "am_neq_full_results_pooled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d720e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_neq_full_results_pooled_df[\"dg std. (kcal/mol)\"] = am_neq_full_results_df[\"dg std. (kcal/mol)\"]\n",
    "apo_neq_full_results_pooled_df[\"dg std. (kcal/mol)\"] = apo_neq_full_results_df[\"dg std. (kcal/mol)\"]\n",
    "nutlin_neq_full_results_pooled_df[\"dg std. (kcal/mol)\"] = nutlin_neq_full_results_df[\"dg std. (kcal/mol)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc75ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "nutlin_neq_full_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd7a9e5",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fced9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_rmse = {}\n",
    "temporal_rmse_lower = {}\n",
    "temporal_rmse_upper = {}\n",
    "temporal_mae = {}\n",
    "\n",
    "\n",
    "time_start_perc = 0 # ns\n",
    "\n",
    "for time_end_perc in range(10, 110, 10):\n",
    "\n",
    "    am_open_slice_results_pooled_df = am_neq_full_results_pooled_df[(am_neq_full_results_pooled_df['time_start_perc'] == 0) & (am_neq_full_results_pooled_df['time_end_perc'] == time_end_perc)]\n",
    "    apo_closed_slice_results_pooled_df = apo_neq_full_results_pooled_df[(apo_neq_full_results_pooled_df['time_start_perc'] == 0) & (apo_neq_full_results_pooled_df['time_end_perc'] == time_end_perc)]\n",
    "    nutlin_closed_slice_results_pooled_df = nutlin_neq_full_results_pooled_df[(nutlin_neq_full_results_pooled_df['time_start_perc'] == 0) & (nutlin_neq_full_results_pooled_df['time_end_perc'] == time_end_perc)]\n",
    "\n",
    "    \n",
    "    am_pred_ddg = am_open_slice_results_pooled_df[\"dG pooled (kcal/mol)\"] - apo_closed_slice_results_pooled_df[\"dG pooled (kcal/mol)\"]\n",
    "    nutlin_pred_ddg = nutlin_closed_slice_results_pooled_df[\"dG pooled (kcal/mol)\"] - apo_closed_slice_results_pooled_df[\"dG pooled (kcal/mol)\"]\n",
    "\n",
    "    am_pred_ddg_std = np.sqrt(am_open_slice_results_pooled_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_pooled_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std = np.sqrt(nutlin_closed_slice_results_pooled_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_pooled_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # am_pred_ddg_std, nutlin_pred_ddg_std\n",
    "\n",
    "    # rename columns\n",
    "    am_pred_ddg = am_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    am_pred_ddg_std = am_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "    nutlin_pred_ddg = nutlin_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    nutlin_pred_ddg_std = nutlin_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "\n",
    "    am_pred_ddg_pooled_df = pd.DataFrame(am_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    am_pred_ddg_std = pd.DataFrame(am_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_pooled_df = pd.DataFrame(nutlin_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_std = pd.DataFrame(nutlin_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "\n",
    "    # reindex the dataframes to match the experimental data\n",
    "    am_pred_ddg_pooled_df.reindex(am_exp_ddg_kcal_df.index)\n",
    "    am_pred_ddg_std.reindex(am_exp_ddg_kcal_df.index)\n",
    "\n",
    "    nutlin_pred_ddg_pooled_df.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "    nutlin_pred_ddg_std.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_pooled_df, nutlin_pred_ddg_pooled_df\n",
    "\n",
    "    predicted_ddg_pooled_df = pd.concat([am_pred_ddg_pooled_df, nutlin_pred_ddg_pooled_df])\n",
    "    predicted_ddg_std_pooled_df = pd.concat([am_pred_ddg_std, nutlin_pred_ddg_std])\n",
    "\n",
    "    experimental_ddg_pooled_df = pd.concat([am_exp_ddg_kcal_df, nutlin_exp_ddg_kcal_df])\n",
    "\n",
    "    # predicted_ddg_pooled_df, experimental_ddg_pooled_df\n",
    "\n",
    "    # to numpy array\n",
    "    predicted_ddg = predicted_ddg_pooled_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    predicted_ddg_std = predicted_ddg_std_pooled_df[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "    experimental_ddg = experimental_ddg_pooled_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "\n",
    "\n",
    "    # predicted_ddg, experimental_ddg\n",
    "\n",
    "    rmse_partial = calculate_rmse(predicted_ddg, experimental_ddg)\n",
    "    mae_partial = calculate_mae(predicted_ddg, experimental_ddg)\n",
    "\n",
    "    # rmse_partial, mae_partial\n",
    "\n",
    "    # convert to numpy arrays for plotting\n",
    "    am_exp_ddg_kcal_np = am_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_np = am_pred_ddg_pooled_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_std_np = am_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    nutlin_exp_ddg_kcal_np = nutlin_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_np = nutlin_pred_ddg_pooled_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_std_np = nutlin_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    temporal_rmse[f\"{time_start_perc}-{time_end_perc}\"] = rmse_partial\n",
    "    temporal_mae[f\"{time_start_perc}-{time_end_perc}\"] = mae_partial\n",
    "    # temporal_std[f\"{time_start_perc}-{time_end_perc}\"] = predicted_ddg_std.mean()\n",
    "\n",
    "\n",
    "    ### PLOT OF Dominant Lid States\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(layout='tight')\n",
    "\n",
    "    x = np.arange(-5, 10, 1)\n",
    "    y = np.arange(-5, 10, 1)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    ax_x_lim, ax_y_lim = -2, 6\n",
    "    padding_x = 0.15\n",
    "\n",
    "\n",
    "\n",
    "    axs.fill_between(x, [i - 1 for i in y], [i + 1 for i in y], alpha=0.2, color='grey')\n",
    "    axs.fill_between(x, [i - 0.5 for i in y], [i + 0.5 for i in y], alpha=0.2, color='grey')\n",
    "    axs.errorbar(x=nutlin_exp_ddg_kcal_np, y=nutlin_pred_ddg_np, yerr=nutlin_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#6fc1dcff', ecolor='black', label='Nutlin-3a')\n",
    "    axs.errorbar(x=am_exp_ddg_kcal_np , y=am_pred_ddg_np, yerr=am_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#F07167', ecolor='black', label='AM-7209')\n",
    "    axs.legend(loc='upper left')\n",
    "    axs.set_ylim(ax_x_lim, ax_y_lim)\n",
    "    axs.set_xlim(ax_x_lim, ax_y_lim)\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.set_ylabel(\"Predicted $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_xlabel(\"Experimental $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_box_aspect(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    axs.annotate('V14G', (nutlin_exp_ddg_kcal_np[0], nutlin_pred_ddg_np[0]), size=12, xytext=(-45, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (nutlin_exp_ddg_kcal_np[1], nutlin_pred_ddg_np[1]), size=12, xytext=(15, -6), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (nutlin_exp_ddg_kcal_np[2], nutlin_pred_ddg_np[2]), size=12, xytext=(-45, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (nutlin_exp_ddg_kcal_np[3], nutlin_pred_ddg_np[3]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (nutlin_exp_ddg_kcal_np[4], nutlin_pred_ddg_np[4]), size=12, xytext=(-80, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.annotate('V14G', (am_exp_ddg_kcal_np [0], am_pred_ddg_np[0]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (am_exp_ddg_kcal_np [1], am_pred_ddg_np[1]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (am_exp_ddg_kcal_np [2], am_pred_ddg_np[2]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (am_exp_ddg_kcal_np [3], am_pred_ddg_np[3]), size=12, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (am_exp_ddg_kcal_np [4], am_pred_ddg_np[4]), size=12, xytext=(15, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    # from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "    # axs.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    # axs.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "    textstr1 = f\"RMSE:      {rmse_partial:.2f}     MAE:      {mae_partial:.2f}\\n\"\n",
    "    textstr = textstr1 \n",
    "    #title = r'MDM2 Dominant Lid States Only (BSS Inputs - Mixture of Replicas)'\n",
    "    title = f'MDM2 NEQ. FEP Dominant State Lid Mutations (N = {len(experimental_ddg)})'\n",
    "    # bootstrap statistics\n",
    "    res_rmse = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='RMSE')\n",
    "    print(res_rmse)\n",
    "    res_mae = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='MUE')\n",
    "    res_rho = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='rho')\n",
    "\n",
    "    # append lower and upper bounds to the dictionary\n",
    "    temporal_rmse_lower[f\"{time_start_perc}-{time_end_perc}\"] = res_rmse['low']\n",
    "    temporal_rmse_upper[f\"{time_start_perc}-{time_end_perc}\"] = res_rmse['high']\n",
    "\n",
    "\n",
    "    textstr = f\"RMSE:        {res_rmse['mle']:.2f} [95%: {res_rmse['low']:.2f}, {res_rmse['high']:.2f}]\\nMAE:        {res_mae['mle']:.2f} [95%: {res_mae['low']:.2f}, {res_mae['high']:.2f}]\\n\"\n",
    "    full_title = f\"{textstr} {title}\"\n",
    "    axs.set_title(full_title, family=\"monospace\", loc='right')\n",
    "    fig.set_size_inches(10,10)\n",
    "    # plt.savefig(f'paper_neq_fep_plots/{time_start_perc}-{time_end_perc}_perc_pooled.pdf', dpi=500, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d97e5",
   "metadata": {},
   "source": [
    "## NEQ Pooled 100 to 10 % (Forward Discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3180015",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutants = [\"v14g\", \"t16g\", \"q18g\", \"i19g\", \"t16g_i19g\"]\n",
    "am_neq_full_results_pooled_df = pd.DataFrame()\n",
    "apo_neq_full_results_pooled_df = pd.DataFrame()\n",
    "nutlin_neq_full_results_pooled_df = pd.DataFrame()\n",
    "\n",
    "time_end = 2750\n",
    "\n",
    "for mutant in mutants:\n",
    "\n",
    "\n",
    "    time_start_slice = [275, 550, 825, 1100, 1375, 1650, 1925, 2200, 2475]\n",
    "    \n",
    "    for time_start in time_start_slice:\n",
    "\n",
    "        am_open_pooled_df = pd.read_csv(f\"neq_xvg_analysis/am_open/system_pooled_results/results_{time_start}_to_{time_end}.dat\",\n",
    "                                names=[\"mutant\", \"dG (kcal/mol)\"])\n",
    "\n",
    "        # Define the string to search for\n",
    "        search_string = rf'\\b{mutant}\\b'\n",
    "\n",
    "        # Apply the string containment check across all elements\n",
    "        contains_string = am_open_pooled_df.applymap(lambda x: specific_pattern_match(x, search_string))\n",
    "\n",
    "        # Filter the DataFrame to get only the rows where any element contains the string\n",
    "        filtered_pooled_df = am_open_pooled_df[contains_string.any(axis=1)]\n",
    "\n",
    "        # Use a regular expression to extract floating point values\n",
    "        # The regex pattern r'([-+]?\\d*\\.\\d+|\\d+)' matches both integers and floating point numbers\n",
    "        filtered_pooled_df['extracted dG (kcal/mol)'] = filtered_pooled_df[\"dG (kcal/mol)\"].str.extract(r'([-+]?\\d*\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "        if len(filtered_pooled_df['extracted dG (kcal/mol)']) != 1 or filtered_pooled_df['extracted dG (kcal/mol)'].isnull().sum() > 0:\n",
    "            raise ValueError(\"The number of extracted values is not equal to 1\")\n",
    "\n",
    "        # Display the DataFrame with the extracted values\n",
    "        # mean_dg = filtered_pooled_df['extracted dG (kcal/mol)'].mean()\n",
    "        # std_dg = filtered_pooled_df['extracted dG (kcal/mol)'].std()\n",
    "        pooled_dg = filtered_pooled_df['extracted dG (kcal/mol)'].tolist()\n",
    "        time_start_perc = time_start / time_end * 100\n",
    "        time_end_perc = 100\n",
    "        processed_pooled_df = pd.DataFrame.from_dict({\"mutant\": mutant, \"dG pooled (kcal/mol)\": pooled_dg[0], \"time_start_perc\": time_start_perc, \"time_end_perc\": time_end_perc}, orient=\"index\").T\n",
    "        am_neq_full_results_pooled_df = pd.concat([am_neq_full_results_pooled_df, processed_pooled_df])\n",
    "        am_neq_full_results_pooled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "for mutant in mutants:\n",
    "\n",
    "    time_start_slice = [275, 550, 825, 1100, 1375, 1650, 1925, 2200, 2475]\n",
    "\n",
    "    for time_start in time_start_slice:\n",
    "\n",
    "        apo_closed_pooled_df = pd.read_csv(f\"neq_xvg_analysis/apo_closed/system_pooled_results/results_{time_start}_to_{time_end}.dat\",\n",
    "                                names=[\"mutant\", \"dG (kcal/mol)\"])\n",
    "\n",
    "        # Define the string to search for\n",
    "        search_string = rf'\\b{mutant}\\b'\n",
    "\n",
    "        # Apply the string containment check across all elements\n",
    "        contains_string = apo_closed_pooled_df.applymap(lambda x: specific_pattern_match(x, search_string))\n",
    "\n",
    "        # Filter the DataFrame to get only the rows where any element contains the string\n",
    "        filtered_pooled_df = apo_closed_pooled_df[contains_string.any(axis=1)]\n",
    "\n",
    "        # Use a regular expression to extract floating point values\n",
    "        # The regex pattern r'([-+]?\\d*\\.\\d+|\\d+)' matches both integers and floating point numbers\n",
    "        filtered_pooled_df['extracted dG (kcal/mol)'] = filtered_pooled_df[\"dG (kcal/mol)\"].str.extract(r'([-+]?\\d*\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "        if len(filtered_pooled_df['extracted dG (kcal/mol)']) != 1 or filtered_pooled_df['extracted dG (kcal/mol)'].isnull().sum() > 0:\n",
    "            raise ValueError(\"The number of extracted values is not equal to 1\")\n",
    "\n",
    "        # Display the DataFrame with the extracted values\n",
    "        # mean_dg = filtered_pooled_df['extracted dG (kcal/mol)'].mean()\n",
    "        # std_dg = filtered_pooled_df['extracted dG (kcal/mol)'].std()\n",
    "        pooled_dg = filtered_pooled_df['extracted dG (kcal/mol)'].tolist()\n",
    "        time_start_perc = time_start / time_end * 100\n",
    "        time_end_perc = 100\n",
    "        processed_pooled_df = pd.DataFrame.from_dict({\"mutant\": mutant, \"dG pooled (kcal/mol)\": pooled_dg[0], \"time_start_perc\": time_start_perc, \"time_end_perc\": time_end_perc}, orient=\"index\").T\n",
    "        apo_neq_full_results_pooled_df = pd.concat([apo_neq_full_results_pooled_df, processed_pooled_df])\n",
    "        apo_neq_full_results_pooled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "for mutant in mutants:\n",
    "\n",
    "    # if mutant == \"t16g_i19g\":\n",
    "    #     time_end = 5250\n",
    "    #     time_start_slice= [525, 1050, 1575, 2100, 2625, 3150, 3675, 4200, 4725]\n",
    "    # else:\n",
    "    #     time_end = 2750\n",
    "    #     time_start_slice = [275, 550, 825, 1100, 1375, 1650, 1925, 2200, 2475]\n",
    "\n",
    "    time_start_slice = [275, 550, 825, 1100, 1375, 1650, 1925, 2200, 2475]\n",
    "\n",
    "    for time_start in time_start_slice:\n",
    "\n",
    "        nutlin_closed_pooled_df = pd.read_csv(f\"neq_xvg_analysis/nutlin_closed/system_pooled_results/results_{time_start}_to_{time_end}.dat\",\n",
    "                                names=[\"mutant\", \"dG (kcal/mol)\"])\n",
    "\n",
    "        # Define the string to search for\n",
    "        search_string = rf'\\b{mutant}\\b'\n",
    "\n",
    "        # Apply the string containment check across all elements\n",
    "        contains_string = nutlin_closed_pooled_df.applymap(lambda x: specific_pattern_match(x, search_string))\n",
    "\n",
    "        # Filter the DataFrame to get only the rows where any element contains the string\n",
    "        filtered_pooled_df = nutlin_closed_pooled_df[contains_string.any(axis=1)]\n",
    "\n",
    "        # Use a regular expression to extract floating point values\n",
    "        # The regex pattern r'([-+]?\\d*\\.\\d+|\\d+)' matches both integers and floating point numbers\n",
    "        filtered_pooled_df['extracted dG (kcal/mol)'] = filtered_pooled_df[\"dG (kcal/mol)\"].str.extract(r'([-+]?\\d*\\.\\d+|\\d+)').astype(float)\n",
    "\n",
    "        if len(filtered_pooled_df['extracted dG (kcal/mol)']) != 1 or filtered_pooled_df['extracted dG (kcal/mol)'].isnull().sum() > 0:\n",
    "            raise ValueError(\"The number of extracted values is not equal to 1\")\n",
    "\n",
    "        # Display the DataFrame with the extracted values\n",
    "        # mean_dg = filtered_pooled_df['extracted dG (kcal/mol)'].mean()\n",
    "        # std_dg = filtered_pooled_df['extracted dG (kcal/mol)'].std()\n",
    "        pooled_dg = filtered_pooled_df['extracted dG (kcal/mol)'].tolist()\n",
    "        time_start_perc = time_start / time_end * 100\n",
    "        time_end_perc = 100\n",
    "        processed_pooled_df = pd.DataFrame.from_dict({\"mutant\": mutant, \"dG pooled (kcal/mol)\": pooled_dg[0], \"time_start_perc\": time_start_perc, \"time_end_perc\": time_end_perc}, orient=\"index\").T\n",
    "        nutlin_neq_full_results_pooled_df = pd.concat([nutlin_neq_full_results_pooled_df, processed_pooled_df])\n",
    "        nutlin_neq_full_results_pooled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# convert dtypes to float\n",
    "am_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"] = am_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"].astype(float)\n",
    "\n",
    "apo_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"] = apo_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"].astype(float)\n",
    "\n",
    "nutlin_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"] = nutlin_neq_full_results_pooled_df[\"dG pooled (kcal/mol)\"].astype(float)\n",
    "\n",
    "am_neq_full_results_pooled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c2eef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use non-pooled data to get the standard deviation\n",
    "am_neq_full_results_pooled_df[\"dg std. (kcal/mol)\"] = am_neq_full_results_df[\"dg std. (kcal/mol)\"]\n",
    "apo_neq_full_results_pooled_df[\"dg std. (kcal/mol)\"] = apo_neq_full_results_df[\"dg std. (kcal/mol)\"]\n",
    "nutlin_neq_full_results_pooled_df[\"dg std. (kcal/mol)\"] = nutlin_neq_full_results_df[\"dg std. (kcal/mol)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9288f0",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7366a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "\n",
    "temporal_rmse = {}\n",
    "temporal_rmse_lower = {}\n",
    "temporal_rmse_upper = {}\n",
    "temporal_mae = {}\n",
    "# temporal_std = {}\n",
    "\n",
    "time_end_perc = 100\n",
    "\n",
    "for time_start_perc in range(10, 100, 10):\n",
    "\n",
    "\n",
    "    am_open_slice_results_pooled_df = am_neq_full_results_pooled_df[(am_neq_full_results_pooled_df['time_start_perc'] == time_start_perc) & (am_neq_full_results_pooled_df['time_end_perc'] == 100)]\n",
    "    apo_closed_slice_results_pooled_df = apo_neq_full_results_pooled_df[(apo_neq_full_results_pooled_df['time_start_perc'] == time_start_perc) & (apo_neq_full_results_pooled_df['time_end_perc'] == 100)]\n",
    "    nutlin_closed_slice_results_pooled_df = nutlin_neq_full_results_pooled_df[(nutlin_neq_full_results_pooled_df['time_start_perc'] == time_start_perc) & (nutlin_neq_full_results_pooled_df['time_end_perc'] == 100)]\n",
    "\n",
    "    \n",
    "    am_pred_ddg = am_open_slice_results_pooled_df[\"dG pooled (kcal/mol)\"] - apo_closed_slice_results_pooled_df[\"dG pooled (kcal/mol)\"]\n",
    "    nutlin_pred_ddg = nutlin_closed_slice_results_pooled_df[\"dG pooled (kcal/mol)\"] - apo_closed_slice_results_pooled_df[\"dG pooled (kcal/mol)\"]\n",
    "\n",
    "    am_pred_ddg_std = np.sqrt(am_open_slice_results_pooled_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_pooled_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std = np.sqrt(nutlin_closed_slice_results_pooled_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_pooled_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # am_pred_ddg_std, nutlin_pred_ddg_std\n",
    "\n",
    "    # rename columns\n",
    "    am_pred_ddg = am_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    am_pred_ddg_std = am_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "    nutlin_pred_ddg = nutlin_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    nutlin_pred_ddg_std = nutlin_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "\n",
    "    am_pred_ddg_df = pd.DataFrame(am_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    am_pred_ddg_std = pd.DataFrame(am_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_df = pd.DataFrame(nutlin_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_std = pd.DataFrame(nutlin_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "\n",
    "    # reindex the dataframes to match the experimental data\n",
    "    am_pred_ddg_df.reindex(am_exp_ddg_kcal_df.index)\n",
    "    am_pred_ddg_std.reindex(am_exp_ddg_kcal_df.index)\n",
    "\n",
    "    nutlin_pred_ddg_df.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "    nutlin_pred_ddg_std.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_df, nutlin_pred_ddg_df\n",
    "\n",
    "    predicted_ddg_df = pd.concat([am_pred_ddg_df, nutlin_pred_ddg_df])\n",
    "    predicted_ddg_std_df = pd.concat([am_pred_ddg_std, nutlin_pred_ddg_std])\n",
    "\n",
    "    experimental_ddg_df = pd.concat([am_exp_ddg_kcal_df, nutlin_exp_ddg_kcal_df])\n",
    "\n",
    "    # predicted_ddg_df, experimental_ddg_df\n",
    "\n",
    "    # to numpy array\n",
    "    predicted_ddg = predicted_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    predicted_ddg_std = predicted_ddg_std_df[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "    experimental_ddg = experimental_ddg_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "\n",
    "\n",
    "    # predicted_ddg, experimental_ddg\n",
    "\n",
    "    rmse_partial = calculate_rmse(predicted_ddg, experimental_ddg)\n",
    "    mae_partial = calculate_mae(predicted_ddg, experimental_ddg)\n",
    "\n",
    "    # rmse_partial, mae_partial\n",
    "\n",
    "    # convert to numpy arrays for plotting\n",
    "    am_exp_ddg_kcal_np = am_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_np = am_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_std_np = am_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    nutlin_exp_ddg_kcal_np = nutlin_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_np = nutlin_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_std_np = nutlin_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    temporal_rmse[f\"{time_start_perc}-{time_end_perc}\"] = rmse_partial\n",
    "    temporal_mae[f\"{time_start_perc}-{time_end_perc}\"] = mae_partial\n",
    "    # temporal_std[f\"{time_start_perc}-{time_end_perc}\"] = predicted_ddg_std.mean()\n",
    "\n",
    "\n",
    "    ### PLOT OF Dominant Lid States\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(layout='tight')\n",
    "\n",
    "    x = np.arange(-5, 10, 1)\n",
    "    y = np.arange(-5, 10, 1)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    ax_x_lim, ax_y_lim = -2, 6\n",
    "    padding_x = 0.15\n",
    "\n",
    "\n",
    "\n",
    "    axs.fill_between(x, [i - 1 for i in y], [i + 1 for i in y], alpha=0.2, color='grey')\n",
    "    axs.fill_between(x, [i - 0.5 for i in y], [i + 0.5 for i in y], alpha=0.2, color='grey')\n",
    "    axs.errorbar(x=nutlin_exp_ddg_kcal_np, y=nutlin_pred_ddg_np, yerr=nutlin_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#6fc1dcff', ecolor='black', label='Nutlin-3a')\n",
    "    axs.errorbar(x=am_exp_ddg_kcal_np , y=am_pred_ddg_np, yerr=am_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#F07167', ecolor='black', label='AM-7209')\n",
    "    axs.legend(loc='upper left')\n",
    "    axs.set_ylim(ax_x_lim, ax_y_lim)\n",
    "    axs.set_xlim(ax_x_lim, ax_y_lim)\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.set_ylabel(\"Predicted $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_xlabel(\"Experimental $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_box_aspect(1)\n",
    "\n",
    "    # texts_nutlin = [axs.text(nutlin_exp_ddg_kcal[i]-padding_x, nutlin_pred_ddg_df[i], f\"{mutations[i]}\", ha='right', va='center') for i in range(len(nutlin_exp_ddg_kcal))]\n",
    "    # texts_am = [axs.text(am_exp_ddg_kcal[i]-padding_x, am_pred_ddg_df[i], f\"{mutations[i]}\", ha='right', va='center') for i in range(len(am_exp_ddg_kcal))]\n",
    "\n",
    "\n",
    "\n",
    "    axs.annotate('V14G', (nutlin_exp_ddg_kcal_np[0], nutlin_pred_ddg_np[0]), size=18, xytext=(-55, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (nutlin_exp_ddg_kcal_np[1], nutlin_pred_ddg_np[1]), size=18, xytext=(7, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (nutlin_exp_ddg_kcal_np[2], nutlin_pred_ddg_np[2]), size=18, xytext=(-55, -7), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (nutlin_exp_ddg_kcal_np[3], nutlin_pred_ddg_np[3]), size=18, xytext=(7, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (nutlin_exp_ddg_kcal_np[4], nutlin_pred_ddg_np[4]), size=18, xytext=(-100, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.annotate('V14G', (am_exp_ddg_kcal_np [0], am_pred_ddg_np[0]), size=18, xytext=(7, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (am_exp_ddg_kcal_np [1], am_pred_ddg_np[1]), size=18, xytext=(7, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (am_exp_ddg_kcal_np [2], am_pred_ddg_np[2]), size=18, xytext=(7, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (am_exp_ddg_kcal_np [3], am_pred_ddg_np[3]), size=18, xytext=(7, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (am_exp_ddg_kcal_np [4], am_pred_ddg_np[4]), size=18, xytext=(15, -5), textcoords=\"offset pixels\")\n",
    "\n",
    "\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    # from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "    # axs.yaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
    "\n",
    "    # bootstrap statistics\n",
    "    res_rmse = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='RMSE')\n",
    "    res_mae = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='MUE')\n",
    "    res_rho = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='rho')\n",
    "    res_r2 = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='R2')\n",
    "    res_ktau = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='KTAU')\n",
    "    print(res_rmse)\n",
    "\n",
    "    # append lower and upper bounds to the dictionary\n",
    "    temporal_rmse_lower[f\"{time_start_ns}-{time_end_ns}\"] = res_rmse['low']\n",
    "    temporal_rmse_upper[f\"{time_start_ns}-{time_end_ns}\"] = res_rmse['high']\n",
    "\n",
    "    textstr = f\"RMSE:        {res_rmse['mle']:.2f} [95%: {res_rmse['low']:.2f}, {res_rmse['high']:.2f}]\\nMAE:        {res_mae['mle']:.2f} [95%: {res_mae['low']:.2f}, {res_mae['high']:.2f}]\\n rho:        {res_rho['mle']:.2f} [95%: {res_rho['low']:.2f}, {res_rho['high']:.2f}]\\n R2:        {res_r2['mle']:.2f} [95%: {res_r2['low']:.2f}, {res_r2['high']:.2f}]\\nKTAU:        {res_ktau['mle']:.2f} [95%: {res_ktau['low']:.2f}, {res_ktau['high']:.2f}]\"\n",
    "    # full_title = f\"{textstr} {title}\"\n",
    "    full_title = f\"{textstr}\"\n",
    "    axs.set_title(full_title, family=\"monospace\", loc='right')\n",
    "    fig.set_size_inches(10,10)\n",
    "    # plt.savefig(f'paper_neq_fep_plots/{time_start_perc}-{time_end_perc}_perc.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77facb32",
   "metadata": {},
   "source": [
    "## FF99SB-ILDN + OPC Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_df_full = pd.read_csv('eq_fep_analysed_results_10_to_100_ff99sb/am_df_full.csv')\n",
    "apo_df_full = pd.read_csv('eq_fep_analysed_results_10_to_100_ff99sb/apo_df_full.csv')\n",
    "nutlin_df_full = pd.read_csv('eq_fep_analysed_results_10_to_100_ff99sb/nutlin_df_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704ffa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f95c61a",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d6531",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=2)\n",
    "\n",
    "temporal_rmse = {}\n",
    "temporal_rmse_lower = {}\n",
    "temporal_rmse_upper = {}\n",
    "temporal_mae = {}\n",
    "temporal_std = {}\n",
    "\n",
    "time_start_ns = 10 # ns\n",
    "\n",
    "for time_end_ns in [100]:\n",
    "    time_end = time_end_ns * 1000 # ns to ps\n",
    "\n",
    "    am_open_slice_results_df = am_df_full[(am_df_full['time_start'] == 10000) & (am_df_full['time_end'] == time_end)]\n",
    "    apo_closed_slice_results_df = apo_df_full[(apo_df_full['time_start'] == 10000) & (apo_df_full['time_end'] == time_end)]\n",
    "    nutlin_closed_slice_results_df = nutlin_df_full[(nutlin_df_full['time_start'] == 10000) & (nutlin_df_full['time_end'] == time_end)]\n",
    "\n",
    "\n",
    "\n",
    "    time_end = time_end_ns * 1000 # ns to ps\n",
    "    am_pred_ddg = am_open_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "    nutlin_pred_ddg = nutlin_closed_slice_results_df[\"dG avg. (kcal/mol)\"] - apo_closed_slice_results_df[\"dG avg. (kcal/mol)\"]\n",
    "\n",
    "    am_pred_ddg_std = np.sqrt(am_open_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "    nutlin_pred_ddg_std = np.sqrt(nutlin_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2 + apo_closed_slice_results_df[\"dg std. (kcal/mol)\"]**2)\n",
    "\n",
    "    # am_pred_ddg_std, nutlin_pred_ddg_std\n",
    "\n",
    "    # rename columns\n",
    "    am_pred_ddg = am_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    am_pred_ddg_std = am_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "    nutlin_pred_ddg = nutlin_pred_ddg.rename(\"ddG avg. (kcal/mol)\")\n",
    "    nutlin_pred_ddg_std = nutlin_pred_ddg_std.rename(\"ddG std. (kcal/mol)\")\n",
    "\n",
    "    print(am_pred_ddg, am_pred_ddg_std)\n",
    "\n",
    "    am_pred_ddg_df = pd.DataFrame(am_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    am_pred_ddg_std = pd.DataFrame(am_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_df = pd.DataFrame(nutlin_pred_ddg, columns=[\"ddG avg. (kcal/mol)\"])\n",
    "    nutlin_pred_ddg_std = pd.DataFrame(nutlin_pred_ddg_std, columns=[\"ddG std. (kcal/mol)\"])\n",
    "\n",
    "    # reindex the dataframes to match the experimental data\n",
    "    am_pred_ddg_df.reindex(am_exp_ddg_kcal_df.index)\n",
    "    am_pred_ddg_std.reindex(am_exp_ddg_kcal_df.index)\n",
    "\n",
    "    nutlin_pred_ddg_df.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "    nutlin_pred_ddg_std.reindex(nutlin_exp_ddg_kcal_df.index)\n",
    "\n",
    "\n",
    "    # am_pred_ddg_df, nutlin_pred_ddg_df\n",
    "\n",
    "    predicted_ddg_df = pd.concat([am_pred_ddg_df, nutlin_pred_ddg_df])\n",
    "    predicted_ddg_std_df = pd.concat([am_pred_ddg_std, nutlin_pred_ddg_std])\n",
    "\n",
    "    experimental_ddg_df = pd.concat([am_exp_ddg_kcal_df, nutlin_exp_ddg_kcal_df])\n",
    "\n",
    "    # predicted_ddg_df, experimental_ddg_df\n",
    "\n",
    "    # to numpy array\n",
    "    predicted_ddg = predicted_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    predicted_ddg_std = predicted_ddg_std_df[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "    experimental_ddg = experimental_ddg_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "\n",
    "\n",
    "    # predicted_ddg, experimental_ddg\n",
    "\n",
    "    rmse_partial = calculate_rmse(predicted_ddg, experimental_ddg)\n",
    "    mae_partial = calculate_mae(predicted_ddg, experimental_ddg)\n",
    "\n",
    "    # rmse_partial, mae_partial\n",
    "\n",
    "    # convert to numpy arrays for plotting\n",
    "    am_exp_ddg_kcal_np = am_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_np = am_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    am_pred_ddg_std_np = am_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    nutlin_exp_ddg_kcal_np = nutlin_exp_ddg_kcal_df[\"ddG (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_np = nutlin_pred_ddg_df[\"ddG avg. (kcal/mol)\"].to_numpy()\n",
    "    nutlin_pred_ddg_std_np = nutlin_pred_ddg_std[\"ddG std. (kcal/mol)\"].to_numpy()\n",
    "\n",
    "    temporal_rmse[f\"{time_start_ns}-{time_end_ns}\"] = rmse_partial\n",
    "    temporal_mae[f\"{time_start_ns}-{time_end_ns}\"] = mae_partial\n",
    "    temporal_std[f\"{time_start_ns}-{time_end_ns}\"] = predicted_ddg_std.mean()\n",
    "\n",
    "\n",
    "    ### PLOT OF Dominant Lid States\n",
    "\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(layout='tight')\n",
    "\n",
    "    x = np.arange(-5, 10, 1)\n",
    "    y = np.arange(-5, 10, 1)\n",
    "    plt.rcParams.update({'font.size': 14})\n",
    "    ax_x_lim, ax_y_lim = -2, 6\n",
    "    padding_x = 0.15\n",
    "\n",
    "\n",
    "\n",
    "    axs.fill_between(x, [i - 1 for i in y], [i + 1 for i in y], alpha=0.2, color='grey')\n",
    "    axs.fill_between(x, [i - 0.5 for i in y], [i + 0.5 for i in y], alpha=0.2, color='grey')\n",
    "    axs.errorbar(x=nutlin_exp_ddg_kcal_np, y=nutlin_pred_ddg_np, yerr=nutlin_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#6fc1dcff', ecolor='black', label='Nutlin-3a')\n",
    "    axs.errorbar(x=am_exp_ddg_kcal_np , y=am_pred_ddg_np, yerr=am_pred_ddg_std_np, fmt='o', mec='black', capsize=6, ms=9, color='#F07167', ecolor='black', label='AM-7209')\n",
    "    axs.legend(loc='upper left')\n",
    "    axs.set_ylim(ax_x_lim, ax_y_lim)\n",
    "    axs.set_xlim(ax_x_lim, ax_y_lim)\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.set_ylabel(\"Predicted $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_xlabel(\"Experimental $\\Delta \\Delta G$ (kcal/mol)\")\n",
    "    axs.set_box_aspect(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    axs.annotate('V14G', (nutlin_exp_ddg_kcal_np[0], nutlin_pred_ddg_np[0]), size=18, xytext=(-50, -15), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (nutlin_exp_ddg_kcal_np[1], nutlin_pred_ddg_np[1]), size=18, xytext=(10, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (nutlin_exp_ddg_kcal_np[2], nutlin_pred_ddg_np[2]), size=18, xytext=(-55, -2), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (nutlin_exp_ddg_kcal_np[3], nutlin_pred_ddg_np[3]), size=18, xytext=(7, -8), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (nutlin_exp_ddg_kcal_np[4], nutlin_pred_ddg_np[4]), size=18, xytext=(-100, -8), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.annotate('V14G', (am_exp_ddg_kcal_np [0], am_pred_ddg_np[0]), size=18, xytext=(7, -3), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G', (am_exp_ddg_kcal_np [1], am_pred_ddg_np[1]), size=18, xytext=(7, -5), textcoords=\"offset pixels\")\n",
    "    axs.annotate('Q18G', (am_exp_ddg_kcal_np [2], am_pred_ddg_np[2]), size=18, xytext=(10, -3), textcoords=\"offset pixels\")\n",
    "    axs.annotate('I19G', (am_exp_ddg_kcal_np [3], am_pred_ddg_np[3]), size=18, xytext=(10, -6), textcoords=\"offset pixels\")\n",
    "    axs.annotate('T16G-I19G', (am_exp_ddg_kcal_np [4], am_pred_ddg_np[4]), size=18, xytext=(10, 2), textcoords=\"offset pixels\")\n",
    "\n",
    "    axs.xaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    axs.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "\n",
    "    # bootstrap statistics\n",
    "    res_rmse = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='RMSE')\n",
    "    res_mae = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='MUE')\n",
    "    res_rho = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='rho')\n",
    "    res_r2 = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='R2')\n",
    "    res_ktau = stats.bootstrap_statistic(y_true=experimental_ddg, y_pred=predicted_ddg, dy_pred=predicted_ddg_std, statistic='KTAU')\n",
    "    print(res_rmse)\n",
    "\n",
    "    # append lower and upper bounds to the dictionary\n",
    "    temporal_rmse_lower[f\"{time_start_ns}-{time_end_ns}\"] = res_rmse['low']\n",
    "    temporal_rmse_upper[f\"{time_start_ns}-{time_end_ns}\"] = res_rmse['high']\n",
    "\n",
    "    textstr = f\"RMSE:        {res_rmse['mle']:.2f} [95%: {res_rmse['low']:.2f}, {res_rmse['high']:.2f}]\\nMAE:        {res_mae['mle']:.2f} [95%: {res_mae['low']:.2f}, {res_mae['high']:.2f}]\\n rho:        {res_rho['mle']:.2f} [95%: {res_rho['low']:.2f}, {res_rho['high']:.2f}]\\n R2:        {res_r2['mle']:.2f} [95%: {res_r2['low']:.2f}, {res_r2['high']:.2f}]\\nKTAU:        {res_ktau['mle']:.2f} [95%: {res_ktau['low']:.2f}, {res_ktau['high']:.2f}]\"\n",
    "    #full_title = f\"{textstr} {title}\"\n",
    "    full_title = f\"{textstr}\"\n",
    "    axs.set_title(full_title, family=\"monospace\", loc='right')\n",
    "    fig.set_size_inches(10,10)\n",
    "    # plt.savefig(f'paper_eq_fep_plots/{time_start_ns}-{time_end_ns}ns_ff99sb.png', dpi=600, bbox_inches='tight')\n",
    "    # plt.savefig(f'paper_eq_fep_plots/{time_start_ns}-{time_end_ns}ns_ff99sb.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee807bab",
   "metadata": {},
   "source": [
    "## Joint Full Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658db9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot with lower and upper bounds\n",
    "from matplotlib.colors import rgb2hex\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "\n",
    "\n",
    "eq_temporal_rmse_forward_df = pd.read_csv('eq_fep_analysed_results_0_to_100_statistics/temporal_rmse_df.csv')\n",
    "eq_temporal_rmse_forward_lower_df = pd.read_csv('eq_fep_analysed_results_0_to_100_statistics/temporal_rmse_lower_df.csv')\n",
    "eq_temporal_rmse_forward_upper_df = pd.read_csv('eq_fep_analysed_results_0_to_100_statistics/temporal_rmse_upper_df.csv')\n",
    "\n",
    "neq_temporal_rmse_forward_df = pd.read_csv('neq_fep_analysed_results_0_to_100_statistics/temporal_rmse_df.csv')\n",
    "neq_temporal_rmse_forward_lower_df = pd.read_csv('neq_fep_analysed_results_0_to_100_statistics/temporal_rmse_lower_df.csv')\n",
    "neq_temporal_rmse_forward_upper_df = pd.read_csv('neq_fep_analysed_results_0_to_100_statistics/temporal_rmse_upper_df.csv')\n",
    "\n",
    "neq_temporal_pooled_rmse_forward_df = pd.read_csv('neq_fep_analysed_results_0_to_100_statistics/temporal_rmse_pooled_df.csv')\n",
    "neq_temporal_pooled_rmse_forward_lower_df = pd.read_csv('neq_fep_analysed_results_0_to_100_statistics/temporal_rmse_lower_pooled_df.csv')\n",
    "neq_temporal_pooled_rmse_forward_upper_df = pd.read_csv('neq_fep_analysed_results_0_to_100_statistics/temporal_rmse_upper_pooled_df.csv')\n",
    "\n",
    "eq_temporal_rmse_reverse_df = pd.read_csv('eq_fep_analysed_results_100_to_10_statistics/temporal_rmse_df.csv')\n",
    "eq_temporal_rmse_reverse_lower_df = pd.read_csv('eq_fep_analysed_results_100_to_10_statistics/temporal_rmse_lower_df.csv')\n",
    "eq_temporal_rmse_reverse_upper_df = pd.read_csv('eq_fep_analysed_results_100_to_10_statistics/temporal_rmse_upper_df.csv')\n",
    "\n",
    "neq_temporal_rmse_reverse_df = pd.read_csv('neq_fep_analysed_results_100_to_10_statistics/temporal_rmse_df.csv')\n",
    "neq_temporal_rmse_reverse_lower_df = pd.read_csv('neq_fep_analysed_results_100_to_10_statistics/temporal_rmse_lower_df.csv')\n",
    "neq_temporal_rmse_reverse_upper_df = pd.read_csv('neq_fep_analysed_results_100_to_10_statistics/temporal_rmse_upper_df.csv')\n",
    "\n",
    "neq_temporal_pooled_rmse_reverse_df = pd.read_csv('neq_fep_analysed_results_100_to_10_statistics/temporal_rmse_pooled_df.csv')\n",
    "neq_temporal_pooled_rmse_reverse_lower_df = pd.read_csv('neq_fep_analysed_results_100_to_10_statistics/temporal_rmse_lower_pooled_df.csv')\n",
    "neq_temporal_pooled_rmse_reverse_upper_df = pd.read_csv('neq_fep_analysed_results_100_to_10_statistics/temporal_rmse_upper_pooled_df.csv')\n",
    "\n",
    "#temporal_rmse_forward_df, temporal_rmse_forward_lower_df, temporal_rmse_forward_upper_df, temporal_rmse_reverse_df, temporal_rmse_reverse_lower_df, temporal_rmse_reverse_upper_df\n",
    "\n",
    "# merge the dataframes\n",
    "eq_temporal_rmse_df = pd.concat([eq_temporal_rmse_forward_df, eq_temporal_rmse_reverse_df], axis=0)\n",
    "eq_temporal_rmse_lower_df = pd.concat([eq_temporal_rmse_forward_lower_df, eq_temporal_rmse_reverse_lower_df], axis=0)\n",
    "eq_temporal_rmse_upper_df = pd.concat([eq_temporal_rmse_forward_upper_df, eq_temporal_rmse_reverse_upper_df], axis=0)\n",
    "\n",
    "neq_temporal_rmse_df = pd.concat([neq_temporal_rmse_forward_df, neq_temporal_rmse_reverse_df], axis=0)\n",
    "neq_temporal_rmse_lower_df = pd.concat([neq_temporal_rmse_forward_lower_df, neq_temporal_rmse_reverse_lower_df], axis=0)\n",
    "neq_temporal_rmse_upper_df = pd.concat([neq_temporal_rmse_forward_upper_df, neq_temporal_rmse_reverse_upper_df], axis=0)\n",
    "\n",
    "neq_temporal_pooled_rmse_df = pd.concat([neq_temporal_pooled_rmse_forward_df, neq_temporal_pooled_rmse_reverse_df], axis=0)\n",
    "neq_temporal_pooled_rmse_lower_df = pd.concat([neq_temporal_pooled_rmse_forward_lower_df, neq_temporal_pooled_rmse_reverse_lower_df], axis=0)\n",
    "neq_temporal_pooled_rmse_upper_df = pd.concat([neq_temporal_pooled_rmse_forward_upper_df, neq_temporal_pooled_rmse_reverse_upper_df], axis=0)\n",
    "\n",
    "# rename the columns\n",
    "eq_temporal_rmse_df.columns = [\"Sampling slice (%)\", \"RMSE (kcal/mol)\"]\n",
    "eq_temporal_rmse_lower_df.columns = [\"Sampling slice (%)\", \"RMSE Lower (kcal/mol)\"]\n",
    "eq_temporal_rmse_upper_df.columns = [\"Sampling slice (%)\", \"RMSE Upper (kcal/mol)\"]\n",
    "\n",
    "neq_temporal_rmse_df.columns = [\"Sampling slice (%)\", \"RMSE (kcal/mol)\"]\n",
    "neq_temporal_rmse_lower_df.columns = [\"Sampling slice (%)\", \"RMSE Lower (kcal/mol)\"]\n",
    "neq_temporal_rmse_upper_df.columns = [\"Sampling slice (%)\", \"RMSE Upper (kcal/mol)\"]\n",
    "\n",
    "neq_temporal_pooled_rmse_df.columns = [\"Sampling slice (%)\", \"RMSE (kcal/mol)\"]\n",
    "neq_temporal_pooled_rmse_lower_df.columns = [\"Sampling slice (%)\", \"RMSE Lower (kcal/mol)\"]\n",
    "neq_temporal_pooled_rmse_upper_df.columns = [\"Sampling slice (%)\", \"RMSE Upper (kcal/mol)\"]\n",
    "\n",
    "\n",
    "eq_temporal_rmse_df = eq_temporal_rmse_df.pivot_table(values='RMSE (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "eq_temporal_rmse_lower_df = eq_temporal_rmse_lower_df.pivot_table(values='RMSE Lower (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "eq_temporal_rmse_upper_df = eq_temporal_rmse_upper_df.pivot_table(values='RMSE Upper (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "\n",
    "neq_temporal_rmse_df = neq_temporal_rmse_df.pivot_table(values='RMSE (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "neq_temporal_rmse_lower_df = neq_temporal_rmse_lower_df.pivot_table(values='RMSE Lower (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "neq_temporal_rmse_upper_df = neq_temporal_rmse_upper_df.pivot_table(values='RMSE Upper (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "\n",
    "neq_temporal_pooled_rmse_df = neq_temporal_pooled_rmse_df.pivot_table(values='RMSE (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "neq_temporal_pooled_rmse_lower_df = neq_temporal_pooled_rmse_lower_df.pivot_table(values='RMSE Lower (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "neq_temporal_pooled_rmse_upper_df = neq_temporal_pooled_rmse_upper_df.pivot_table(values='RMSE Upper (kcal/mol)', columns='Sampling slice (%)', sort=False)\n",
    "\n",
    "\n",
    "# reverse the palette\n",
    "aerospace_orange = \"#FF4F00\"\n",
    "\n",
    "# plot a line plot with the lower and upper bounds\n",
    "fig, axs = plt.subplots(ncols=3, nrows=1, figsize=(20, 7), sharey=True,)\n",
    "\n",
    "axs[0].plot(eq_temporal_rmse_df.T, alpha=1, color=aerospace_orange, linewidth=2)\n",
    "axs[0].plot(eq_temporal_rmse_upper_df.T, alpha=0.0,)\n",
    "axs[0].plot(eq_temporal_rmse_lower_df.T, alpha=0.0)\n",
    "\n",
    "line = axs[0].get_lines()\n",
    "axs[0].fill_between(line[0].get_xdata(), line[1].get_ydata(), line[2].get_ydata(), alpha=.4, color=aerospace_orange)\n",
    "\n",
    "# add a grey horizontal line at 1\n",
    "axs[0].axhline(y=1, color='grey', linestyle='--')\n",
    "axs[0].margins(x=0.0)\n",
    "axs[0].tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "\n",
    "axs[1].plot(neq_temporal_rmse_df.T, alpha=1, color=aerospace_orange, linewidth=2)\n",
    "axs[1].plot(neq_temporal_rmse_upper_df.T, alpha=0.0,)\n",
    "axs[1].plot(neq_temporal_rmse_lower_df.T, alpha=0.0)\n",
    "\n",
    "line = axs[1].get_lines()\n",
    "axs[1].fill_between(line[0].get_xdata(), line[1].get_ydata(), line[2].get_ydata(), alpha=.4, color=aerospace_orange)\n",
    "axs[1].axhline(y=1, color='grey', linestyle='--')\n",
    "axs[1].margins(x=0.0)\n",
    "axs[1].tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "\n",
    "axs[2].plot(neq_temporal_pooled_rmse_df.T, alpha=1, color=aerospace_orange, linewidth=2)\n",
    "axs[2].plot(neq_temporal_pooled_rmse_upper_df.T, alpha=0.0,)\n",
    "axs[2].plot(neq_temporal_pooled_rmse_lower_df.T, alpha=0.0)\n",
    "\n",
    "line = axs[2].get_lines()\n",
    "axs[2].fill_between(line[1].get_xdata(), line[1].get_ydata(), line[2].get_ydata(), alpha=.4, color=aerospace_orange)\n",
    "axs[2].axhline(y=1, color='grey', linestyle='--')\n",
    "axs[2].margins(x=0.0)\n",
    "axs[2].tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "\n",
    "# add axis labels\n",
    "axs[0].set_ylabel(\"G RMSE (kcal/mol)\")\n",
    "axs[0].set_xlabel(\"Portion of Total Sampling Time (%)\")\n",
    "axs[1].set_xlabel(\"Portion of Total Sampling Time (%)\")\n",
    "axs[2].set_xlabel(\"Portion of Total Sampling Time (%)\")\n",
    "\n",
    "\n",
    "axs[0].set_title(\"EQ\", fontsize=25, font='monospace')\n",
    "axs[1].set_title(\"NEQ\", fontsize=25, font='monospace')\n",
    "axs[2].set_title(\"NEQ Pooled\", fontsize=16, font='monospace')\n",
    "\n",
    "# fix y-limit to 0\n",
    "axs[0].set_ylim(0, axs[0].get_ylim()[1])\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.savefig('paper_combined_fep_plots/combined_temporal_rmse_lineplot.png', dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b49e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_am_std_forward_df = pd.read_csv('eq_fep_analysed_results_0_to_100_statistics/temporal_am_pred_ddg_std_df.csv')\n",
    "eq_am_std_reverse_df = pd.read_csv('eq_fep_analysed_results_100_to_10_statistics/temporal_am_pred_ddg_std_df.csv')\n",
    "eq_nutlin_std_forward_df = pd.read_csv('eq_fep_analysed_results_0_to_100_statistics/temporal_nutlin_pred_ddg_std_df.csv')\n",
    "eq_nutlin_std_reverse_df = pd.read_csv('eq_fep_analysed_results_100_to_10_statistics/temporal_nutlin_pred_ddg_std_df.csv')\n",
    "\n",
    "neq_am_std_forward_df = pd.read_csv('neq_fep_analysed_results_0_to_100_statistics/temporal_am_pred_ddg_std_df.csv')\n",
    "neq_am_std_reverse_df = pd.read_csv('neq_fep_analysed_results_100_to_10_statistics/temporal_am_pred_ddg_std_df.csv')\n",
    "neq_nutlin_std_forward_df = pd.read_csv('neq_fep_analysed_results_0_to_100_statistics/temporal_nutlin_pred_ddg_std_df.csv')\n",
    "neq_nutlin_std_reverse_df = pd.read_csv('neq_fep_analysed_results_100_to_10_statistics/temporal_nutlin_pred_ddg_std_df.csv')\n",
    "\n",
    "# merge the dataframes\n",
    "eq_am_std_df = pd.concat([eq_am_std_forward_df, eq_am_std_reverse_df], axis=0)\n",
    "eq_nutlin_std_df = pd.concat([eq_nutlin_std_forward_df, eq_nutlin_std_reverse_df], axis=0)\n",
    "neq_am_std_df = pd.concat([neq_am_std_forward_df, neq_am_std_reverse_df], axis=0)\n",
    "neq_nutlin_std_df = pd.concat([neq_nutlin_std_forward_df, neq_nutlin_std_reverse_df], axis=0)\n",
    "\n",
    "# convert values to percentages for eq only, since the neq values are already in percentages\n",
    "eq_am_std_df['time_start_perc'] = eq_am_std_df['time_start'] / 1000\n",
    "eq_am_std_df['time_end_perc'] = eq_am_std_df['time_end'] / 1000\n",
    "\n",
    "eq_nutlin_std_df['time_start_perc'] = eq_nutlin_std_df['time_start'] / 1000\n",
    "eq_nutlin_std_df['time_end_perc'] = eq_nutlin_std_df['time_end'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the dataframes\n",
    "combined_eq_std_df = pd.concat([eq_am_std_df, eq_nutlin_std_df], axis=0)\n",
    "combined_neq_std_df = pd.concat([neq_am_std_df, neq_nutlin_std_df], axis=0)\n",
    "\n",
    "# convert column values to int, then string\n",
    "combined_eq_std_df['time_start_perc'] = combined_eq_std_df['time_start_perc'].astype(int)\n",
    "combined_eq_std_df['time_end_perc'] = combined_eq_std_df['time_end_perc'].astype(int)\n",
    "combined_eq_std_df['time_start_perc'] = combined_eq_std_df['time_start_perc'].astype(str)\n",
    "combined_eq_std_df['time_end_perc'] = combined_eq_std_df['time_end_perc'].astype(str)\n",
    "\n",
    "combined_neq_std_df['time_start_perc'] = combined_neq_std_df['time_start_perc'].astype(int)\n",
    "combined_neq_std_df['time_end_perc'] = combined_neq_std_df['time_end_perc'].astype(int)\n",
    "combined_neq_std_df['time_start_perc'] = combined_neq_std_df['time_start_perc'].astype(str)\n",
    "combined_neq_std_df['time_end_perc'] = combined_neq_std_df['time_end_perc'].astype(str)\n",
    "\n",
    "# combine values from two columns\n",
    "combined_eq_std_df['Sampling slice (%)'] = combined_eq_std_df['time_start_perc'] + \"-\" + combined_eq_std_df['time_end_perc']\n",
    "combined_neq_std_df['Sampling slice (%)'] = combined_neq_std_df['time_start_perc'] + \"-\" + combined_neq_std_df['time_end_perc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f304dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change mutant names to uppercase\n",
    "combined_eq_std_df['mutant'] = combined_eq_std_df['mutant'].str.upper()\n",
    "combined_neq_std_df['mutant'] = combined_neq_std_df['mutant'].str.upper()\n",
    "\n",
    "# for T16G_I19G, change to T16G-I19G\n",
    "combined_eq_std_df.loc[combined_eq_std_df[\"mutant\"] == \"T16G_I19G\", \"mutant\"] = \"T16G-I19G\"\n",
    "combined_neq_std_df.loc[combined_neq_std_df[\"mutant\"] == \"T16G_I19G\", \"mutant\"] = \"T16G-I19G\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3110223",
   "metadata": {},
   "outputs": [],
   "source": [
    "grape = \"#6F2DA8\"\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "\n",
    "\n",
    "palette = sns.color_palette(\"Dark2\", 5)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, nrows=1, figsize=(20, 7), sharey=True)\n",
    "\n",
    "\n",
    "sns.lineplot(data=combined_eq_std_df, x=combined_eq_std_df['Sampling slice (%)'], y=combined_eq_std_df['ddg std. (kcal/mol)'], hue=combined_eq_std_df['mutant'], ax=axs[0], palette=palette, marker='o', linestyle='--', errorbar=None)\n",
    "sns.lineplot(data=combined_eq_std_df, x=combined_eq_std_df['Sampling slice (%)'], y=combined_eq_std_df['ddg std. (kcal/mol)'], hue=None, ax=axs[0], color=grape, linewidth=2, errorbar=None, label=\"Combined\")\n",
    "sns.lineplot(data=combined_neq_std_df, x=combined_neq_std_df['Sampling slice (%)'], y=combined_neq_std_df['ddg std. (kcal/mol)'], hue=combined_neq_std_df['mutant'], ax=axs[1], palette=palette, marker='o', linestyle='--', errorbar=None)\n",
    "sns.lineplot(data=combined_neq_std_df, x=combined_neq_std_df['Sampling slice (%)'], y=combined_neq_std_df['ddg std. (kcal/mol)'], hue=None, ax=axs[1], color=grape, linewidth=2, errorbar=None, label=\"Combined\")\n",
    "\n",
    "\n",
    "# add axis labels\n",
    "axs[0].set_ylabel(\"G Mean SD (kcal/mol)\")\n",
    "axs[0].set_xlabel(\"Portion of Total Sampling Time (%)\")\n",
    "axs[1].set_xlabel(\"Portion of Total Sampling Time (%)\")\n",
    "\n",
    "\n",
    "axs[0].legend(loc='upper left', frameon=False)\n",
    "axs[1].legend(loc='upper left', frameon=False)\n",
    "\n",
    "axs[0].tick_params(axis='x', labelrotation=90)\n",
    "axs[1].tick_params(axis='x', labelrotation=90)\n",
    "\n",
    "axs[0].set_title(\"EQ\", fontsize=16, font='monospace')\n",
    "axs[1].set_title(\"NEQ\", fontsize=16,font='monospace')\n",
    "\n",
    "# fix y-limit to 0\n",
    "axs[0].set_ylim(0, axs[0].get_ylim()[1])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('paper_combined_fep_plots/combined_temporal_std_lineplot.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e664f3",
   "metadata": {},
   "source": [
    "## NEQ Overlap Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc66b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "apo_neq_full_results_df = pd.DataFrame()\n",
    "\n",
    "for mutant in [\"v14g\", \"t16g\", \"q18g\", \"i19g\", \"i19g_1ns\", \"i61g\", \"i99g\", \"t16g_i19g\"]:\n",
    "    print(f\"Processing mutant: {mutant}\")\n",
    "\n",
    "    time_start = 0\n",
    "    time_end_slice = [2750]\n",
    "\n",
    "\n",
    "    for time_end in time_end_slice:\n",
    "\n",
    "        apo_closed_df = pd.read_csv(f\"neq_xvg_analysis/apo_closed/system_results/results_0_{time_end}_mod.dat\",\n",
    "                        names=[\"mutant\", \"dG (kcal/mol)\"])\n",
    "\n",
    "        # Define the string to search for\n",
    "        search_string = rf'\\b{mutant}_repl_\\d+\\b'\n",
    "\n",
    "        # Apply the string containment check across all elements\n",
    "        contains_string = apo_closed_df.applymap(lambda x: specific_pattern_match(x, search_string))\n",
    "\n",
    "        # Filter the DataFrame to get only the rows where any element contains the string\n",
    "        filtered_df = apo_closed_df[contains_string.any(axis=1)]\n",
    "\n",
    "        # Use a regular expression to extract floating point values\n",
    "        # The regex pattern r'([-+]?\\d*\\.\\d+|\\d+)' matches both integers and floating point numbers\n",
    "        filtered_df['extracted dG (kcal/mol)'] = filtered_df[\"dG (kcal/mol)\"].str.extract(r'([-+]?\\d*\\.\\d+|\\d+)').astype(float)\n",
    "        print(filtered_df)\n",
    "\n",
    "\n",
    "        if len(filtered_df['extracted dG (kcal/mol)']) != 5 or filtered_df['extracted dG (kcal/mol)'].isnull().sum() > 0:\n",
    "            raise ValueError(\"The number of extracted values is not equal to 5\")\n",
    "\n",
    "        # Display the DataFrame with the extracted values\n",
    "        mean_dg = filtered_df['extracted dG (kcal/mol)'].mean()\n",
    "        std_dg = filtered_df['extracted dG (kcal/mol)'].std()\n",
    "        time_end_perc = time_end / time_end_slice[-1] * 100\n",
    "        processed_df = pd.DataFrame.from_dict({\"mutant\": mutant, \"dG avg. (kcal/mol)\": mean_dg, \"dg std. (kcal/mol)\": std_dg, \"time_start_perc\": time_start, \"time_end_perc\": time_end_perc}, orient=\"index\").T\n",
    "        apo_neq_full_results_df = pd.concat([apo_neq_full_results_df, processed_df])\n",
    "        apo_neq_full_results_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f180b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "\n",
    "for mutant in [\"v14g\", \"t16g\", \"q18g\", \"i19g\", \"i19g_1ns\", \"i61g\", \"i99g\",  \"t16g_i19g\"]:\n",
    "\n",
    "    std_df = apo_neq_full_results_df[(apo_neq_full_results_df['time_start_perc'] == 0) & (apo_neq_full_results_df['time_end_perc'] == 100)]\n",
    "    std_df = std_df[std_df['mutant'] == mutant]\n",
    "    std_mut = std_df['dg std. (kcal/mol)'].values[0]\n",
    "    std_mut = std_mut.round(2)\n",
    "\n",
    "\n",
    "    work_dir = f\"neq_xvg_analysis/apo_closed/system_pooled_results/{mutant}/results_0_to_2750_pooled\"\n",
    "\n",
    "    forward_work_df = pd.read_csv(f\"{work_dir}/integA.dat\", sep=\"\\s+\", names=[\"Snapshot\", \"Work (kJ/mol)\"])\n",
    "    forward_work_df[\"Direction\"] = \"forward\"\n",
    "\n",
    "    # convert the work to kcal/mol\n",
    "    forward_work_df[\"Work (kcal/mol)\"] = arr_to_kJ2kcal(forward_work_df[\"Work (kJ/mol)\"]) \n",
    "\n",
    "    reverse_work_df = pd.read_csv(f\"{work_dir}/integB.dat\", sep=\"\\s+\", names=[\"Snapshot\", \"Work (kJ/mol)\"])\n",
    "    reverse_work_df[\"Direction\"] = \"reverse\"\n",
    "\n",
    "\n",
    "    reverse_work_df[\"Work (kcal/mol)\"] = arr_to_kJ2kcal(reverse_work_df[\"Work (kJ/mol)\"]) \n",
    "\n",
    "    # accesss each frame and split the frame number the full path to the frame\n",
    "    forward_work_df[\"Snapshot\"] = forward_work_df[\"Snapshot\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])\n",
    "    reverse_work_df[\"Snapshot\"] = reverse_work_df[\"Snapshot\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])\n",
    "\n",
    "    forward_work_df\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "    ax1 = sns.histplot(data=forward_work_df, x='Work (kcal/mol)', stat=\"density\", bins=40, kde=True, ax=ax1, label=\"Forward\", color=\"#6F2DA8\", alpha=0.7, edgecolor='black')\n",
    "    ax1 = sns.histplot(data=reverse_work_df, x='Work (kcal/mol)', stat=\"density\", bins=40, kde=True, ax=ax1, label=\"Reverse\", color=\"#FF4F00\", alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel(\"Work (kcal/mol)\")\n",
    "    ax1.text(0.5, 0.9, f'SD:{std_mut} kcal/mol', horizontalalignment='center', verticalalignment='center', transform=ax1.transAxes, font=\"monospace\", bbox=dict(edgecolor=\"black\", fill=False, alpha=1))\n",
    "\n",
    "    # set title\n",
    "    if mutant == \"i19g_1ns\":\n",
    "        mutant_title = \"i19g (1ns)\"\n",
    "    elif mutant == \"t16g_i19g\":\n",
    "        mutant_title = \"t16g-i19g\"\n",
    "    else:\n",
    "        mutant_title = mutant\n",
    "    ax1.set_title(f\"{mutant_title.upper()}\", font=\"monospace\")\n",
    "    ax1.legend(loc='upper left', edgecolor='black')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
